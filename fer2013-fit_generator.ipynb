{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/75-soa/fer2013-fit_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "outputId": "144c82eb-82b8-4e1e-b17a-2e5588a38f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%tensorflow_version 1.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.4`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "outputId": "00ab8aed-1159-4037-a16a-c1495472139c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.lib.io import file_io\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI204HIYEdLE",
        "colab_type": "code",
        "outputId": "c3d81ac7-7a04-4c69-dc15-6838b4a2ad4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hAjh6yOLYPZm",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
        "def get_data(dataset):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "                        rescale=1./255,\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "            dataset,\n",
        "            target_size=(48, 48),\n",
        "            color_mode='grayscale',\n",
        "            shuffle = False,\n",
        "            class_mode='categorical',\n",
        "            batch_size=32)\n",
        "\n",
        "    X_train = train_generator\n",
        "    Y_train = train_generator.classes    \n",
        "    return  X_train, Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm5tqGr-zHsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b32610fd-1114-419f-c600-0d32d3b94cc9"
      },
      "source": [
        "training_dataset_dir = '/content/drive/My Drive/cs230 project/dataset/webcam'\n",
        "dev_dataset_dir = '/content/drive/My Drive/cs230 project/dataset/webcam' #TODO split into dev/test folders\n",
        "\n",
        "X_train, Y_train  = get_data(training_dataset_dir)\n",
        "X_dev, Y_dev      = get_data(dev_dataset_dir)\n",
        "\n",
        "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
        "# rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
        "# rotation_range:   Int. Degree range for random rotations\n",
        "# shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
        "# zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
        "# fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
        "# horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rotation_range  = 10,\n",
        "#     shear_range     = 5, # 10 degrees\n",
        "#     zoom_range      = 0.1,\n",
        "#     fill_mode       = 'reflect',\n",
        "#     horizontal_flip = True)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#         rotation_range=15,\n",
        "#         width_shift_range=0.2,\n",
        "#         height_shift_range=0.2,\n",
        "#         horizontal_flip=True,\n",
        "#         zoom_range=0.2)\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#                         featurewise_center=False,\n",
        "#                         featurewise_std_normalization=False,\n",
        "#                         rotation_range=10,\n",
        "#                         width_shift_range=0.1,\n",
        "#                         height_shift_range=0.1,\n",
        "#                         zoom_range=.1,\n",
        "#                         horizontal_flip=True)\n",
        "\n",
        "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "# x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "#               it should have value 3\n",
        "# y:            Labels\n",
        "# batch_size:   Int (default: 32)\n",
        "#train_generator = train_datagen.flow(X_train, Y_train,  batch_size  = BS)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 130 images belonging to 7 classes.\n",
            "Found 130 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPO33wZKzHsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "BS = 128\n",
        "DROPOUT_RATE = 0.4\n",
        "SGD_LEARNING_RATE = 0.01\n",
        "SGD_DECAY = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG4t-6RO-g2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement below paper CPCPCPFF depth 5, 2.4m params\n",
        "# http://openaccess.thecvf.com/content_cvpr_2016_workshops/w28/papers/Kim_Fusing_Aligned_and_CVPR_2016_paper.pdf\n",
        "# Reference: https://arxiv.org/pdf/1612.02903.pdf\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), activation='relu',padding='same', input_shape=(48,48,1),name=\"conv1\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name=\"maxpool1\"))\n",
        "#model.add(Dropout(DROPOUT_RATE))\n",
        "model.add(Conv2D(32, (4, 4), activation='relu',padding='same',name=\"conv2\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name=\"maxpool2\"))         \n",
        "#model.add(Dropout(DROPOUT_RATE))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu',padding='same',name=\"conv3\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name=\"maxpool3\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu',name='fc1'))\n",
        "model.add(Dropout(DROPOUT_RATE))\n",
        "model.add(Dense(7, activation='softmax',name='fcsoftmax'))\n",
        "\n",
        "#TODO: weight decay of 0.0001...initial learning rate is set to 0.01 and reduced by a factor of 2 at every 25 epoch\n",
        "sgd = SGD(lr=SGD_LEARNING_RATE,momentum=0.9, decay=SGD_DECAY, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
        "#rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=100)\n",
        "rlrop = ReduceLROnPlateau(monitor='val_acc',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ3hGX2HzHsw",
        "colab_type": "code",
        "outputId": "d73605c9-fd66-4da4-b98a-9ef2aa7a33db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# history = model.fit_generator(\n",
        "#     generator = X_train,\n",
        "#     validation_data=(X_dev, Y_dev), \n",
        "#     steps_per_epoch=len(X_train) // BS,\n",
        "#     shuffle=True,\n",
        "#     epochs=EPOCHS,\n",
        "#     callbacks=[rlrop]) \n",
        "\n",
        "history = model.fit_generator(\n",
        "    generator = X_train,\n",
        "    epochs=EPOCHS)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 209ms/step - loss: 9.0054 - acc: 0.0649\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 6.2580 - acc: 0.3380\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 6.3245 - acc: 0.2925\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 5.8467 - acc: 0.3510\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 4.9982 - acc: 0.4288\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 5.1653 - acc: 0.2731\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 4.7225 - acc: 0.3769\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 4.2260 - acc: 0.4418\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 4.0025 - acc: 0.4353\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 3.2044 - acc: 0.4937\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 3.4593 - acc: 0.3572\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 3.2141 - acc: 0.4678\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 3.5232 - acc: 0.3897\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 3.8792 - acc: 0.4288\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 4.4329 - acc: 0.4224\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 3.4633 - acc: 0.4224\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 3.1827 - acc: 0.4548\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 2.5054 - acc: 0.5132\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 2.4976 - acc: 0.3702\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 2.0671 - acc: 0.4873\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 1.9525 - acc: 0.3637\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1.7274 - acc: 0.4548\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1.7960 - acc: 0.4613\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.4473 - acc: 0.4937\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 2.5024 - acc: 0.4675\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 1.6530 - acc: 0.5392\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 1.5598 - acc: 0.5522\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 2.1640 - acc: 0.4740\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 1.2162 - acc: 0.5522\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 1.4806 - acc: 0.5197\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 1.3164 - acc: 0.6300\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 1.2935 - acc: 0.5716\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.9243 - acc: 0.6560\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1.0086 - acc: 0.6820\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.9451 - acc: 0.6690\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.8038 - acc: 0.7209\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.7444 - acc: 0.7079\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.9245 - acc: 0.6950\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 1.1329 - acc: 0.6430\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.7610 - acc: 0.7079\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.7045 - acc: 0.7339\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.7502 - acc: 0.7339\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.7591 - acc: 0.7599\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.7580 - acc: 0.7209\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.7764 - acc: 0.7404\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.6174 - acc: 0.7404\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.6893 - acc: 0.7728\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.8668 - acc: 0.7274\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.8568 - acc: 0.7534\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.7103 - acc: 0.7469\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.6461 - acc: 0.7599\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.6542 - acc: 0.7339\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.7441 - acc: 0.6623\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.7181 - acc: 0.7988\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.6366 - acc: 0.7209\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.5651 - acc: 0.7858\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.4542 - acc: 0.8377\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.6319 - acc: 0.7793\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.5792 - acc: 0.8183\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.5726 - acc: 0.7663\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4363 - acc: 0.8572\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4571 - acc: 0.8442\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.3834 - acc: 0.8507\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.6061 - acc: 0.7339\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.5595 - acc: 0.8248\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4185 - acc: 0.8312\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.4468 - acc: 0.8248\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.4836 - acc: 0.8053\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.3531 - acc: 0.8442\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.4364 - acc: 0.8377\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.5384 - acc: 0.8183\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.3174 - acc: 0.8572\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.3781 - acc: 0.8832\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.3492 - acc: 0.8442\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.3652 - acc: 0.8702\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.3528 - acc: 0.8767\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.4635 - acc: 0.8118\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4269 - acc: 0.8183\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2370 - acc: 0.9091\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.2628 - acc: 0.8897\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.3303 - acc: 0.8832\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.3618 - acc: 0.8702\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.4642 - acc: 0.8702\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2010 - acc: 0.9416\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2876 - acc: 0.8897\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.2824 - acc: 0.8897\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.2597 - acc: 0.9156\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.3491 - acc: 0.8767\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.3071 - acc: 0.8962\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1975 - acc: 0.9416\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.2693 - acc: 0.9026\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.2596 - acc: 0.9026\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.2327 - acc: 0.9156\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.2165 - acc: 0.9156\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.2298 - acc: 0.9481\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.3409 - acc: 0.8572\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.2056 - acc: 0.9091\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.2018 - acc: 0.9675\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.2645 - acc: 0.9026\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.2815 - acc: 0.9286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-FSBxRPXHSZE",
        "outputId": "cdce1f17-399d-46fc-d2c8-5af76aa53243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "results_dev = model.evaluate_generator(X_dev)\n",
        "print(\"Accuracy on dev set: {:.2%}\".format(results_dev[1]))\n",
        "results_test = results_dev\n",
        "print(\"Accuracy on test set: {:.2%}\".format(results_test[1]))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on dev set: 74.62%\n",
            "Accuracy on test set: 74.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr6u8rO4zHtH",
        "colab_type": "code",
        "outputId": "62afff18-2f1f-4016-f40a-be13f37b6462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-8a82a978eaa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEJEif8HfKSsGhU9rEkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pQfysJQzHtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_str = '-SGD_LR_%.5f' % SGD_LEARNING_RATE\n",
        "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
        "bs_str = '-BS_' + str(BS)\n",
        "dropout_str = '-DROPOUT_' + str(DROPOUT_RATE)\n",
        "test_acc = 'test_acc_%.3f' % results_test[1]\n",
        "model.save('/content/drive/My Drive/cs230 project/models/soa' + lr_str + epoch_str + bs_str + dropout_str + test_acc + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMAJ9smqKdD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# configure image data augmentation\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "# make a prediction using test-time augmentation\n",
        "def tta_prediction(datagen, model, image, n_examples):\n",
        "\t# convert image into dataset\n",
        "\tsamples = np.expand_dims(image, 0)\n",
        "\t# prepare iterator\n",
        "\tit = datagen.flow(samples, batch_size=n_examples)\n",
        "\t# make predictions for each augmented image\n",
        "\tyhats = model.predict_generator(it, steps=n_examples, verbose=0)\n",
        "\t# sum across predictions\n",
        "\tsummed = np.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\treturn np.argmax(summed)\n",
        " \n",
        " # evaluate a model on a dataset using test-time augmentation\n",
        "def tta_evaluate_model(model, testX, testY):\n",
        "\t# configure image data augmentation\n",
        "\tdatagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\t# define the number of augmented images to generate per test set image\n",
        "\tn_examples_per_image = 7\n",
        "\tyhats = list()\n",
        "\tfor i in range(len(testX)):\n",
        "\t\t# make augmented prediction\n",
        "\t\tyhat = tta_prediction(datagen, model, testX[i], n_examples_per_image)\n",
        "\t\t# store for evaluation\n",
        "\t\tyhats.append(yhat)\n",
        "\t# calculate accuracy\n",
        "\ttestY_labels = np.argmax(testY, axis=1)\n",
        "\tacc = accuracy_score(testY_labels, yhats)\n",
        "\treturn acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfTihcArMdUk",
        "colab_type": "code",
        "outputId": "82bcb68b-0155-4bc3-eb6a-55b480809cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "TTA_results_test = tta_evaluate_model(model, X_test, Y_test)\n",
        "print('test loss, test acc:', results_test)\n",
        "print('TTA test acc:', TTA_results_test)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-47f55bc342ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n# Evaluate on test data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTTA_results_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtta_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test loss, test acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TTA test acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTTA_results_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    }
  ]
}