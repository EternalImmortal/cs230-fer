{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow_p36)",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/transfer-learning/fer2013_Charles_VGG_with_class_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras-vggface\n",
        "!pip install scikit-image\n",
        "!pip install pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.python.lib.io import file_io\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import *\n",
        "from keras.engine import Model\n",
        "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
        "import skimage\n",
        "from skimage.transform import rescale, resize\n",
        "\n",
        "import pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZczU8lGkX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUcd6yIGduUW",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60q28mDHnN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10\n",
        "BS = 128\n",
        "DROPOUT_RATE = 0.5\n",
        "FROZEN_LAYER_NUM = 19\n",
        "\n",
        "ADAM_LEARNING_RATE = 0.001\n",
        "SGD_LEARNING_RATE = 0.01\n",
        "SGD_DECAY = 0.0001\n",
        "\n",
        "Resize_pixelsize = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itKZtFV0F7b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_notop = VGGFace(model='vgg16', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n",
        "print(vgg_notop.summary())\n",
        "last_layer = vgg_notop.get_layer('pool5').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(1024, activation='relu', name='fc7')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "\n",
        "for i in range(FROZEN_LAYER_NUM):\n",
        "    vgg_notop.layers[i].trainable = False\n",
        "\n",
        "print(vgg_notop.get_layer('pool5').trainable)\n",
        "\n",
        "out = Dense(7, activation='softmax', name='classifier')(x)\n",
        "\n",
        "model = Model(vgg_notop.input, out)\n",
        "\n",
        "\n",
        "optim = keras.optimizers.Adam(lr=ADAM_LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "sgd = keras.optimizers.SGD(lr=SGD_LEARNING_RATE, momentum=0.9, decay=SGD_DECAY, nesterov=True)\n",
        "rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_acc',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
        "\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "colab": {}
      },
      "source": [
        "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
        "def get_data(dataset, bs=32, aug=None, pixelsize=Resize_pixelsize):\n",
        "    # Data preparation\n",
        "    while True:\n",
        "      file_stream = file_io.FileIO(dataset, mode='r')\n",
        "      datas = pd.read_csv(file_stream,iterator=True, chunksize=bs )\n",
        "      for data in datas:\n",
        "          data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "          X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "          X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "          X = X/255.0\n",
        "          X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "          for ind in range(X.shape[0]): \n",
        "              sample = X[ind]\n",
        "              sample = sample.reshape(48, 48)\n",
        "              image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "              X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "          Y_res = np.zeros((Y.size, 7))\n",
        "          Y_res[np.arange(Y.size),Y] = 1\n",
        "          if aug is not None:\n",
        "              (X_res, Y_res) = next(aug.flow(np.array(X_res),\n",
        "                  Y_res, batch_size=bs))\n",
        "          yield  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQkWIk2kF0aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/train.csv'\n",
        "dev_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/dev.csv'\n",
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "#    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = get_data(training_dataset_dir,  bs=BS, aug=aug)\n",
        "dev_generator   = get_data(dev_dataset_dir, bs=BS, aug=None)\n",
        "test_generator   = get_data(test_dataset_dir, bs=BS, aug=None)\n",
        "    #X_dev_res, Y_dev_res  = get_data(dev_dataset_dir)\n",
        "\n",
        "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
        "# rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
        "# rotation_range:   Int. Degree range for random rotations\n",
        "# shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
        "# zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
        "# fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
        "# horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
        "\n",
        "\n",
        "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "#train_generator = train_datagen.flow(X_train_res, Y_train_res,  batch_size  = BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2kuzhHorLEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "file_stream = file_io.FileIO('/content/drive/My Drive/cs230 project/collab/fer2013/dev.csv', mode='r')\n",
        "data = pd.read_csv(file_stream)\n",
        "\n",
        "#data = pd.read_csv('fer2013/fer2013.csv')\n",
        "data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "\n",
        "# Retrieve train input and target\n",
        "X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                    np.unique(Y),\n",
        "                                                    Y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pLISdlaStbUn",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator = train_generator,\n",
        "    validation_data=dev_generator, \n",
        "    steps_per_epoch=28709// BS,\n",
        "    validation_steps=3509 // BS,\n",
        "    shuffle=True,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[rlrop],\n",
        "    use_multiprocessing=True,\n",
        "    class_weight=class_weights\n",
        ") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSSv08SHF0bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on dev data')\n",
        "results_dev = model.evaluate_generator(dev_generator, 3509 // BS)\n",
        "print('dev loss, dev acc:', results_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4sDYDlOsqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "results_test = model.evaluate_generator(test_generator, 3509 // BS)\n",
        "print('test loss, test acc:', results_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9f7smhHUQus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QKHTmJQhi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_str = '-SGD_LR_%.5f' % SGD_LEARNING_RATE\n",
        "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
        "bs_str = '-BS_' + str(BS)\n",
        "dropout_str = '-DROPOUT_' + str(DROPOUT_RATE)\n",
        "test_acc = '-test_acc_%.3f' % results_test[1]\n",
        "model.save('/content/drive/My Drive/cs230 project/models/tl/senet50-tl' + lr_str + epoch_str + bs_str + dropout_str + test_acc + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqHDa5Hwiih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_for_test(dataset, pixelsize = Resize_pixelsize):\n",
        "    file_stream = file_io.FileIO(dataset, mode='r')\n",
        "    data = pd.read_csv(file_stream)\n",
        "    data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "\n",
        "    X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "    X = X/255.0\n",
        "    X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "    for ind in range(X.shape[0]):  #X_dev.shape[0]\n",
        "        sample = X[ind]\n",
        "        sample = sample.reshape(48, 48)\n",
        "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "        X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "    Y_res = np.zeros((Y.size, Y.max()+1))\n",
        "    Y_res[np.arange(Y.size),Y] = 1\n",
        "    \n",
        "    return  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MAUWRXFxcm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "X_test_res, Y_test_res  = get_data_for_test(test_dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulH4ikEJxhm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test_res, Y_test_res)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cHBx0OcUYWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# configure image data augmentation\n",
        "tta_aug = ImageDataGenerator(\n",
        "    # rotation_range  = 10,\n",
        "    # shear_range     = 10, # 10 degrees\n",
        "    # zoom_range      = 0.1,\n",
        "    # fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "# make a prediction using test-time augmentation\n",
        "def tta_prediction(model, image, n_examples):\n",
        "\t# convert image into dataset\n",
        "\tsamples = np.expand_dims(image, 0)\n",
        "  test_generator = get_data(test_dataset_dir, bs=BS, aug=tta_aug)\n",
        "\tit = test_generator.flow(samples, batch_size=n_examples)\n",
        "\tyhats = model.predict_generator(it, steps=n_examples, verbose=0)\n",
        "\t# sum across predictions\n",
        "\tsummed = np.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\treturn np.argmax(summed)\n",
        " \n",
        " # evaluate a model on a dataset using test-time augmentation\n",
        "def tta_evaluate_model(model, testX, testY):\n",
        "\t# configure image data augmentation\n",
        "\tdatagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\t# define the number of augmented images to generate per test set image\n",
        "\tn_examples_per_image = 7\n",
        "\tyhats = list()\n",
        "\tfor i in range(len(testX)):\n",
        "\t\t# make augmented prediction\n",
        "\t\tyhat = tta_prediction(datagen, model, testX[i], n_examples_per_image)\n",
        "\t\t# store for evaluation\n",
        "\t\tyhats.append(yhat)\n",
        "\t# calculate accuracy\n",
        "\ttestY_labels = np.argmax(testY, axis=1)\n",
        "\tacc = accuracy_score(testY_labels, yhats)\n",
        "\treturn acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78X7l-0txbT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ia-TsrIUf9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "TTA_results_test = tta_evaluate_model(model, X_test, Y_test)\n",
        "print('test loss, test acc:', results_test)\n",
        "print('TTA test acc:', TTA_results_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}