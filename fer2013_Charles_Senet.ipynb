{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow_p36)",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/transfer-learning/fer2013_Charles_Senet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "outputId": "98b8ce66-57e9-487b-f38c-5b7545371566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras-vggface\n",
        "!pip install scikit-image\n",
        "!pip install pydot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/7d/5f0319ebdc09ac1a2272364fa9583f5067b6f8aff93fbbf8835d81cbaad7/keras_vggface-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.12.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (6.2.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.17.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.1.0)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (6.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.1.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.17.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (45.2.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "outputId": "df920af7-ed39-40e7-9133-75affd2bbe57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.python.lib.io import file_io\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import *\n",
        "from keras.engine import Model\n",
        "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
        "import skimage\n",
        "from skimage.transform import rescale, resize\n",
        "\n",
        "import pydot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZczU8lGkX-",
        "colab_type": "code",
        "outputId": "be585882-d263-4939-9fa4-f7ccdb196f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUcd6yIGduUW",
        "outputId": "dced1acd-15ac-4ced-c741-1d39ae44b37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60q28mDHnN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "BS = 128\n",
        "DROPOUT_RATE = 0.5\n",
        "FROZEN_LAYER_NUM = 101\n",
        "\n",
        "ADAM_LEARNING_RATE = 0.001\n",
        "SGD_LEARNING_RATE = 0.01\n",
        "SGD_DECAY = 0.0001\n",
        "\n",
        "Resize_pixelsize = 197"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itKZtFV0F7b1",
        "colab_type": "code",
        "outputId": "203698db-7e08-4604-ae00-d091b159a53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg_notop = VGGFace(model='senet50', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n",
        "last_layer = vgg_notop.get_layer('avg_pool').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(4096, activation='relu', name='fc6')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(1024, activation='relu', name='fc7')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "    \n",
        "batch_norm_indices = [2, 6, 9, 12, 21, 25, 28, 31, 42, 45, 48, 59, 62, 65, 74, 78, 81, 84, 95, 98, 101, 112, 115, 118, 129, 132, 135, 144, 148, 151, 154, 165, 168, 171, 182, 185, 188, 199, 202, 205, 216, 219, 222, 233, 236, 239, 248, 252, 255, 258, 269, 272, 275]\n",
        "for i in range(FROZEN_LAYER_NUM):\n",
        "    if i not in batch_norm_indices:\n",
        "        vgg_notop.layers[i].trainable = False\n",
        "# print('vgg layer 2 is trainable: ' + str(vgg_notop.layers[2].trainable))\n",
        "# print('vgg layer 3 is trainable: ' + str(vgg_notop.layers[3].trainable))\n",
        "\n",
        "out = Dense(7, activation='softmax', name='classifier')(x)\n",
        "\n",
        "model = Model(vgg_notop.input, out)\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "optim = keras.optimizers.Adam(lr=ADAM_LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "sgd = keras.optimizers.SGD(lr=SGD_LEARNING_RATE, momentum=0.9, decay=SGD_DECAY, nesterov=True)\n",
        "rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_acc',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
        "\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# plot_model(model, to_file='model2.png', show_shapes=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 99, 99, 64)   9408        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 99, 99, 64)   256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 99, 99, 64)   0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 49, 49, 64)   0           activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 49, 49, 64)   4096        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 49, 49, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 49, 49, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_52 (Gl (None, 256)          0           conv2_1_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_49 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_52[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_down (Conv2D)       (None, 1, 1, 16)     4112        reshape_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 1, 1, 16)     0           conv2_1_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_up (Conv2D)         (None, 1, 1, 256)    4352        activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 1, 1, 256)    0           conv2_1_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 49, 49, 256)  16384       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "multiply_49 (Multiply)          (None, 49, 49, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 49, 49, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 49, 49, 256)  0           multiply_49[0][0]                \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 49, 49, 256)  0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 49, 49, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 49, 49, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_53 (Gl (None, 256)          0           conv2_2_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_50 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_53[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_down (Conv2D)       (None, 1, 1, 16)     4112        reshape_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 1, 1, 16)     0           conv2_2_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_up (Conv2D)         (None, 1, 1, 256)    4352        activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 1, 1, 256)    0           conv2_2_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_50 (Multiply)          (None, 49, 49, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 49, 49, 256)  0           multiply_50[0][0]                \n",
            "                                                                 activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 49, 49, 256)  0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 49, 49, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 49, 49, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_54 (Gl (None, 256)          0           conv2_3_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_51 (Reshape)            (None, 1, 1, 256)    0           global_average_pooling2d_54[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_down (Conv2D)       (None, 1, 1, 16)     4112        reshape_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 1, 1, 16)     0           conv2_3_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_up (Conv2D)         (None, 1, 1, 256)    4352        activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 1, 1, 256)    0           conv2_3_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_51 (Multiply)          (None, 49, 49, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 49, 49, 256)  0           multiply_51[0][0]                \n",
            "                                                                 activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 49, 49, 256)  0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 25, 25, 128)  32768       activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 25, 25, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 25, 25, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_55 (Gl (None, 512)          0           conv3_1_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_52 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_55[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 1, 1, 32)     0           conv3_1_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 1, 1, 512)    0           conv3_1_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 25, 25, 512)  131072      activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_52 (Multiply)          (None, 25, 25, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 25, 25, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 25, 25, 512)  0           multiply_52[0][0]                \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 25, 25, 512)  0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 25, 25, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 25, 25, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_56 (Gl (None, 512)          0           conv3_2_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_53 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_56[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 1, 1, 32)     0           conv3_2_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 1, 1, 512)    0           conv3_2_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_53 (Multiply)          (None, 25, 25, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 25, 25, 512)  0           multiply_53[0][0]                \n",
            "                                                                 activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 25, 25, 512)  0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 25, 25, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 25, 25, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_57 (Gl (None, 512)          0           conv3_3_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_54 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_57[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 1, 1, 32)     0           conv3_3_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 1, 1, 512)    0           conv3_3_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_54 (Multiply)          (None, 25, 25, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 25, 25, 512)  0           multiply_54[0][0]                \n",
            "                                                                 activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 25, 25, 512)  0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 25, 25, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 25, 25, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_58 (Gl (None, 512)          0           conv3_4_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_55 (Reshape)            (None, 1, 1, 512)    0           global_average_pooling2d_58[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_down (Conv2D)       (None, 1, 1, 32)     16416       reshape_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 1, 1, 32)     0           conv3_4_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_up (Conv2D)         (None, 1, 1, 512)    16896       activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 1, 1, 512)    0           conv3_4_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_55 (Multiply)          (None, 25, 25, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 25, 25, 512)  0           multiply_55[0][0]                \n",
            "                                                                 activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 25, 25, 512)  0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 13, 13, 256)  131072      activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 13, 13, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 13, 13, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_59 (Gl (None, 1024)         0           conv4_1_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_56 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_59[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 1, 1, 64)     0           conv4_1_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 1, 1, 1024)   0           conv4_1_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 13, 13, 1024) 524288      activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_56 (Multiply)          (None, 13, 13, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 13, 13, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 13, 13, 1024) 0           multiply_56[0][0]                \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 13, 13, 1024) 0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 13, 13, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 13, 13, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_60 (Gl (None, 1024)         0           conv4_2_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_57 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_60[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 1, 1, 64)     0           conv4_2_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 1, 1, 1024)   0           conv4_2_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_57 (Multiply)          (None, 13, 13, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 13, 13, 1024) 0           multiply_57[0][0]                \n",
            "                                                                 activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 13, 13, 1024) 0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 13, 13, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 13, 13, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_61 (Gl (None, 1024)         0           conv4_3_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_58 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_61[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 1, 1, 64)     0           conv4_3_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 1, 1, 1024)   0           conv4_3_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_58 (Multiply)          (None, 13, 13, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 13, 13, 1024) 0           multiply_58[0][0]                \n",
            "                                                                 activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 13, 13, 1024) 0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 13, 13, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 13, 13, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_62 (Gl (None, 1024)         0           conv4_4_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_59 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_62[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 1, 1, 64)     0           conv4_4_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 1, 1, 1024)   0           conv4_4_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_59 (Multiply)          (None, 13, 13, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 13, 13, 1024) 0           multiply_59[0][0]                \n",
            "                                                                 activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 13, 13, 1024) 0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 13, 13, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 13, 13, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_63 (Gl (None, 1024)         0           conv4_5_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_60 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_63[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 1, 1, 64)     0           conv4_5_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 1, 1, 1024)   0           conv4_5_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_60 (Multiply)          (None, 13, 13, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 13, 13, 1024) 0           multiply_60[0][0]                \n",
            "                                                                 activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 13, 13, 1024) 0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 13, 13, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 13, 13, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_64 (Gl (None, 1024)         0           conv4_6_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_61 (Reshape)            (None, 1, 1, 1024)   0           global_average_pooling2d_64[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_down (Conv2D)       (None, 1, 1, 64)     65600       reshape_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 1, 1, 64)     0           conv4_6_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_up (Conv2D)         (None, 1, 1, 1024)   66560       activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 1, 1, 1024)   0           conv4_6_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_61 (Multiply)          (None, 13, 13, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 13, 13, 1024) 0           multiply_61[0][0]                \n",
            "                                                                 activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 13, 13, 1024) 0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_65 (Gl (None, 2048)         0           conv5_1_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_62 (Reshape)            (None, 1, 1, 2048)   0           global_average_pooling2d_65[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_down (Conv2D)       (None, 1, 1, 128)    262272      reshape_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 1, 1, 128)    0           conv5_1_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_up (Conv2D)         (None, 1, 1, 2048)   264192      activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 1, 1, 2048)   0           conv5_1_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_62 (Multiply)          (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 7, 7, 2048)   0           multiply_62[0][0]                \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 7, 7, 2048)   0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_66 (Gl (None, 2048)         0           conv5_2_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_63 (Reshape)            (None, 1, 1, 2048)   0           global_average_pooling2d_66[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_down (Conv2D)       (None, 1, 1, 128)    262272      reshape_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 1, 1, 128)    0           conv5_2_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_up (Conv2D)         (None, 1, 1, 2048)   264192      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 1, 1, 2048)   0           conv5_2_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_63 (Multiply)          (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 7, 7, 2048)   0           multiply_63[0][0]                \n",
            "                                                                 activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 7, 7, 2048)   0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_67 (Gl (None, 2048)         0           conv5_3_1x1_increase/bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_64 (Reshape)            (None, 1, 1, 2048)   0           global_average_pooling2d_67[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_down (Conv2D)       (None, 1, 1, 128)    262272      reshape_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 1, 1, 128)    0           conv5_3_1x1_down[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_up (Conv2D)         (None, 1, 1, 2048)   264192      activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 1, 1, 2048)   0           conv5_3_1x1_up[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_64 (Multiply)          (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 7, 7, 2048)   0           multiply_64[0][0]                \n",
            "                                                                 activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 7, 7, 2048)   0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 2048)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc6 (Dense)                     (None, 4096)         8392704     dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 4096)         0           fc6[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 1024)         4195328     dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 1024)         0           fc7[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 7)            7175        dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 38,687,351\n",
            "Trainable params: 37,385,927\n",
            "Non-trainable params: 1,301,424\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "colab": {}
      },
      "source": [
        "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
        "def get_data(dataset, bs=32, aug=None, pixelsize=Resize_pixelsize):\n",
        "    # Data preparation\n",
        "    while True:\n",
        "      file_stream = file_io.FileIO(dataset, mode='r')\n",
        "      datas = pd.read_csv(file_stream,iterator=True, chunksize=bs )\n",
        "      for data in datas:\n",
        "          data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "          X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "          X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "          X = X/255.0\n",
        "          X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "          for ind in range(X.shape[0]): \n",
        "              sample = X[ind]\n",
        "              sample = sample.reshape(48, 48)\n",
        "              image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "              X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "          Y_res = np.zeros((Y.size, Y.max()+1))\n",
        "          Y_res[np.arange(Y.size),Y] = 1\n",
        "          if aug is not None:\n",
        "              (X_res, Y_res) = next(aug.flow(np.array(X_res),\n",
        "                  Y_res, batch_size=bs))\n",
        "          yield  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQkWIk2kF0aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/train.csv'\n",
        "dev_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/dev.csv'\n",
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "#    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = get_data(training_dataset_dir,  bs=BS, aug=aug)\n",
        "dev_generator   = get_data(dev_dataset_dir, bs=BS, aug=None)\n",
        "test_generator   = get_data(test_dataset_dir, bs=BS, aug=None)\n",
        "    #X_dev_res, Y_dev_res  = get_data(dev_dataset_dir)\n",
        "\n",
        "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
        "# rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
        "# rotation_range:   Int. Degree range for random rotations\n",
        "# shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
        "# zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
        "# fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
        "# horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
        "\n",
        "\n",
        "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "#train_generator = train_datagen.flow(X_train_res, Y_train_res,  batch_size  = BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pLISdlaStbUn",
        "outputId": "fa575dc1-06cc-4aa8-96f7-caa8d9a5a38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator = train_generator,\n",
        "    validation_data=dev_generator, \n",
        "    steps_per_epoch=28709// BS,\n",
        "    validation_steps=3509 // BS,\n",
        "    shuffle=True,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[rlrop],\n",
        "    use_multiprocessing=True,\n",
        ") "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "224/224 [==============================] - 377s 2s/step - loss: 2.0477 - acc: 0.2251 - val_loss: 1.8334 - val_acc: 0.2494\n",
            "Epoch 2/20\n",
            "223/224 [============================>.] - ETA: 1s - loss: 1.6524 - acc: 0.3316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cabc5e91c19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrlrop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m ) \n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    235\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    238\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msteps_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         x, y, sample_weights = self._standardize_user_data(\n\u001b[1;32m   1481\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected classifier to have shape (7,) but got array with shape (5,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSSv08SHF0bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on dev data')\n",
        "results_dev = model.evaluate_generator(dev_generator, 3509 // BS)\n",
        "print('dev loss, dev acc:', results_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4sDYDlOsqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "results_test = model.evaluate_generator(test_generator, 3509 // BS)\n",
        "print('test loss, test acc:', results_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9f7smhHUQus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QKHTmJQhi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_str = '-SGD_LR_%.5f' % SGD_LEARNING_RATE\n",
        "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
        "bs_str = '-BS_' + str(BS)\n",
        "dropout_str = '-DROPOUT_' + str(DROPOUT_RATE)\n",
        "test_acc = 'test_acc_%.3f' % results_test[1]\n",
        "model.save('/content/drive/My Drive/cs230 project/models/tl/tl' + lr_str + epoch_str + bs_str + dropout_str + test_acc + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqHDa5Hwiih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_for_test(dataset, pixelsize = Resize_pixelsize):\n",
        "    file_stream = file_io.FileIO(dataset, mode='r')\n",
        "    data = pd.read_csv(file_stream)\n",
        "    data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "\n",
        "    X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "    X = X/255.0\n",
        "    X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "    for ind in range(X.shape[0]):  #X_dev.shape[0]\n",
        "        sample = X[ind]\n",
        "        sample = sample.reshape(48, 48)\n",
        "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "        X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "    Y_res = np.zeros((Y.size, Y.max()+1))\n",
        "    Y_res[np.arange(Y.size),Y] = 1\n",
        "    \n",
        "    return  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MAUWRXFxcm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "X_test_res, Y_test_res  = get_data_for_test(test_dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulH4ikEJxhm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test_res, Y_test_res)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cHBx0OcUYWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# configure image data augmentation\n",
        "tta_aug = ImageDataGenerator(\n",
        "    # rotation_range  = 10,\n",
        "    # shear_range     = 10, # 10 degrees\n",
        "    # zoom_range      = 0.1,\n",
        "    # fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "# make a prediction using test-time augmentation\n",
        "def tta_prediction(model, image, n_examples):\n",
        "\t# convert image into dataset\n",
        "\tsamples = np.expand_dims(image, 0)\n",
        "  test_generator = get_data(test_dataset_dir, bs=BS, aug=tta_aug)\n",
        "\tit = test_generator.flow(samples, batch_size=n_examples)\n",
        "\tyhats = model.predict_generator(it, steps=n_examples, verbose=0)\n",
        "\t# sum across predictions\n",
        "\tsummed = np.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\treturn np.argmax(summed)\n",
        " \n",
        " # evaluate a model on a dataset using test-time augmentation\n",
        "def tta_evaluate_model(model, testX, testY):\n",
        "\t# configure image data augmentation\n",
        "\tdatagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\t# define the number of augmented images to generate per test set image\n",
        "\tn_examples_per_image = 7\n",
        "\tyhats = list()\n",
        "\tfor i in range(len(testX)):\n",
        "\t\t# make augmented prediction\n",
        "\t\tyhat = tta_prediction(datagen, model, testX[i], n_examples_per_image)\n",
        "\t\t# store for evaluation\n",
        "\t\tyhats.append(yhat)\n",
        "\t# calculate accuracy\n",
        "\ttestY_labels = np.argmax(testY, axis=1)\n",
        "\tacc = accuracy_score(testY_labels, yhats)\n",
        "\treturn acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78X7l-0txbT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ia-TsrIUf9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "TTA_results_test = tta_evaluate_model(model, X_test, Y_test)\n",
        "print('test loss, test acc:', results_test)\n",
        "print('TTA test acc:', TTA_results_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}