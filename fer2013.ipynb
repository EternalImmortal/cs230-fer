{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/master/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "gwdg7Sv3XBaP",
    "outputId": "67a02583-ad88-4944-8cef-2aa337461771"
   },
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow-gpu==2.0  #unnecessary on aws if using conda_tensorflow2_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nz38mJZXN_P"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, InputLayer, MaxPool2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EjKPXZ3TX3Jb",
    "outputId": "ee914feb-7007-4255-c019-acf871c03c6d"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013/fer2013.csv')\n",
    "\n",
    "#print('Number of samples in the dataset: ', data.shape[0])\n",
    "emotion_cat = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n",
    "\n",
    "# See the target distribution (check for imbalance)\n",
    "#target_counts = data['emotion'].value_counts().reset_index(drop=False)\n",
    "#target_counts.columns = ['emotion', 'number_samples']\n",
    "#target_counts['emotion'] = target_counts['emotion'].map(emotion_cat)\n",
    "#target_counts\n",
    "\n",
    "# Transform images from strings to lists of integers. TODO: use an array cast\n",
    "data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "id": "oXIX_VLMYJty",
    "outputId": "72fd8418-a4eb-4798-febc-5f2b241ed60a"
   },
   "outputs": [],
   "source": [
    "# Select randomly 10 images\n",
    "#random_seed = 1\n",
    "#data_sample = data.sample(10, random_state=random_seed)\n",
    "#f, axarr = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "#i, j = 0, 0\n",
    "#for idx, row in data_sample.iterrows():\n",
    "#    img = np.array(row['pixels']).reshape(48,48)\n",
    "#    axarr[i,j].imshow(img, cmap='gray')\n",
    "#    axarr[i,j].set_title(emotion_cat[row['emotion']])\n",
    "#    if j==4:\n",
    "#        i += 1\n",
    "#        j = 0\n",
    "#    else:\n",
    "#        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hAjh6yOLYPZm",
    "outputId": "ff38d494-272d-4907-f10d-399249d9d181"
   },
   "outputs": [],
   "source": [
    "data_train = data[data['Usage']=='Training']\n",
    "size_train = data_train.shape[0]\n",
    "#print('Number samples in the training dataset: ', size_train)\n",
    "\n",
    "data_dev = data[data['Usage']=='PublicTest']\n",
    "size_dev = data_dev.shape[0]\n",
    "#print('Number samples in the development dataset: ', size_dev)\n",
    "\n",
    "# Retrieve train input and target\n",
    "X_train, y_train = data_train['pixels'].tolist(), data_train['emotion'].values\n",
    "# Reshape images to 4D (num_samples, width, height, num_channels)\n",
    "X_train = np.array(X_train, dtype='float32').reshape(-1,48,48,1)\n",
    "# Normalize images with max (the maximum pixel intensity is 255)\n",
    "X_train = X_train/255.0\n",
    "\n",
    "# Retrieve dev input and target\n",
    "X_dev, y_dev = data_dev['pixels'].tolist(), data_dev['emotion'].values\n",
    "# Reshape images to 4D (num_samples, width, height, num_channels)\n",
    "X_dev = np.array(X_dev, dtype='float32').reshape(-1,48,48,1)\n",
    "# Normalize images with max\n",
    "X_dev = X_dev/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi3lopGhZIuT"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(   \n",
    "    [\n",
    "     InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
    "     Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
    "     Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
    "     MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
    "     Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
    "     Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
    "     Flatten(),\n",
    "     Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
    "     Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rP81tUpXaORF"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "k_KuMIRrfQKj",
    "outputId": "34801006-d971-4e14-c454-552ef3d2cb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              37749760  \n",
      "_________________________________________________________________\n",
      "fc-softmax (Dense)           (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 37,821,927\n",
      "Trainable params: 37,821,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "a_WbRvBwfRlA",
    "outputId": "9c6eb46a-9fc0-4882-c49a-20708c2b161b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples\n",
      "Epoch 1/10\n",
      "28709/28709 [==============================] - 92s 3ms/sample - loss: 1.5997 - accuracy: 0.3674\n",
      "Epoch 2/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 1.2936 - accuracy: 0.5067\n",
      "Epoch 3/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.9818 - accuracy: 0.6314\n",
      "Epoch 4/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.5055 - accuracy: 0.8225\n",
      "Epoch 5/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.1582 - accuracy: 0.9560\n",
      "Epoch 6/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.0822 - accuracy: 0.9833\n",
      "Epoch 7/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.0609 - accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.0513 - accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.0574 - accuracy: 0.9886\n",
      "Epoch 10/10\n",
      "28709/28709 [==============================] - 30s 1ms/sample - loss: 0.0468 - accuracy: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec7ff85b38>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=32,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKzZuMBafv0a"
   },
   "outputs": [],
   "source": [
    "y_hat_dev = np.argmax(model.predict(X_dev), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qS5D2ykHhgCz",
    "outputId": "69badeee-4c98-4797-8d18-80e99fe217ca",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5182502089718585"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "sm.accuracy_score(y_hat_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP3ARIJt1LIfH+r42VxlMaB",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1Rx-Px8_AwlXFnxbs2AlsUJ-2BIIfqmVT",
   "name": "fer2013.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
