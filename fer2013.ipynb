{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow2_p36)",
      "language": "python",
      "name": "conda_tensorflow2_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/master/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "outputId": "278f5f07-f33f-427c-982e-c563eee96653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%tensorflow_version 2.x #!pip3 install tensorflow-gpu==2.0  #unnecessary on aws if using conda_tensorflow2_p36"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.x #!pip3 install tensorflow-gpu==2.0  #unnecessary on aws if using conda_tensorflow2_p36`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "outputId": "1bfef23a-648f-48df-8228-f0e2c344b028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/cs230 project/collab/fer2013/fer2013.csv')\n",
        "\n",
        "#data = pd.read_csv('fer2013/fer2013.csv')\n",
        "\n",
        "#print('Number of samples in the dataset: ', data.shape[0])\n",
        "emotion_cat = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n",
        "\n",
        "# See the target distribution (check for imbalance)\n",
        "#target_counts = data['emotion'].value_counts().reset_index(drop=False)\n",
        "#target_counts.columns = ['emotion', 'number_samples']\n",
        "#target_counts['emotion'] = target_counts['emotion'].map(emotion_cat)\n",
        "#target_counts\n",
        "\n",
        "# Transform images from strings to lists of integers. TODO: use an array cast\n",
        "data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXIX_VLMYJty",
        "colab": {}
      },
      "source": [
        "# Select randomly 10 images\n",
        "#random_seed = 1\n",
        "#data_sample = data.sample(10, random_state=random_seed)\n",
        "#f, axarr = plt.subplots(2, 5, figsize=(20, 10))\n",
        "\n",
        "#i, j = 0, 0\n",
        "#for idx, row in data_sample.iterrows():\n",
        "#    img = np.array(row['pixels']).reshape(48,48)\n",
        "#    axarr[i,j].imshow(img, cmap='gray')\n",
        "#    axarr[i,j].set_title(emotion_cat[row['emotion']])\n",
        "#    if j==4:\n",
        "#        i += 1\n",
        "#        j = 0\n",
        "#    else:\n",
        "#        j += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hAjh6yOLYPZm",
        "colab": {}
      },
      "source": [
        "data_train = data[data['Usage']=='Training']\n",
        "size_train = data_train.shape[0]\n",
        "#print('Number samples in the training dataset: ', size_train)\n",
        "\n",
        "data_dev = data[data['Usage']=='PublicTest']\n",
        "size_dev = data_dev.shape[0]\n",
        "#print('Number samples in the development dataset: ', size_dev)\n",
        "\n",
        "# Retrieve train input and target\n",
        "X_train, y_train = data_train['pixels'].tolist(), data_train['emotion'].values\n",
        "# Reshape images to 4D (num_samples, width, height, num_channels)\n",
        "X_train = np.array(X_train, dtype='float32').reshape(-1,48,48,1)\n",
        "# Normalize images with max (the maximum pixel intensity is 255)\n",
        "X_train = X_train/255.0\n",
        "\n",
        "# Retrieve dev input and target\n",
        "X_dev, y_dev = data_dev['pixels'].tolist(), data_dev['emotion'].values\n",
        "# Reshape images to 4D (num_samples, width, height, num_channels)\n",
        "X_dev = np.array(X_dev, dtype='float32').reshape(-1,48,48,1)\n",
        "# Normalize images with max\n",
        "X_dev = X_dev/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yi3lopGhZIuT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2bacf30-501a-42f7-801c-dd807d15de56"
      },
      "source": [
        "#Do it yourself model\n",
        "model_diy = tf.keras.models.Sequential([\n",
        "    InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
        "    Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
        "])\n",
        "\n",
        "print(\"Accuracy after training\")\n",
        "model_diy.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iKzZuMBafv0a",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3f37fcaa-4478-4d56-edda-23420c8fb0b0"
      },
      "source": [
        "model_diy.fit(X_train,y_train,batch_size=32,epochs=5)\n",
        "y_hat_dev = np.argmax(model_diy.predict(X_dev), axis=1)\n",
        "\n",
        "sm.accuracy_score(y_hat_dev, y_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples\n",
            "Epoch 1/5\n",
            "15200/28709 [==============>...............] - ETA: 15s - loss: 1.8063 - accuracy: 0.3213"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVlZENbEpiyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}