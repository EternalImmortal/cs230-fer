{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/transfer-learning/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwdg7Sv3XBaP"
   },
   "outputs": [],
   "source": [
    "#tensorflow_version 1.x\n",
    "#!pip install keras-vggface\n",
    "#!conda install scikit-image\n",
    "#!conda install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nz38mJZXN_P"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import *\n",
    "from keras.engine import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try:\n",
    "    pydot.Dot.create(pydot.Dot())\n",
    "except:\n",
    "    print('pydot error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nUcd6yIGduUW",
    "outputId": "94e06002-1afb-4fab-b6fc-f69cef85fa1c"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013/icml_face_data.csv', sep=r'\\s*,\\s*', header=0, encoding='ascii', engine='python')\n",
    "data.head()\n",
    "\n",
    "data_train = data[data['Usage'] == 'Training']\n",
    "#print('Number samples in the training dataset: ', data_train.shape[0])\n",
    "\n",
    "data_dev = data[data['Usage'] == 'PublicTest']\n",
    "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
    "print(data_dev.head())\n",
    "\n",
    "data_test = data[data['Usage'] == 'PrivateTest']\n",
    "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
    "print(data_test.head())\n",
    "\n",
    "data_train.to_csv('fer2013/train.csv')\n",
    "data_dev.to_csv('fer2013/dev.csv')\n",
    "data_test.to_csv('fer2013/test.csv')\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_dev.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EarfWgg_Y4rR",
    "outputId": "a053f8b0-3c50-46bd-abc3-19e52a91aed0"
   },
   "outputs": [],
   "source": [
    "Resize_pixelsize = 197\n",
    "vgg_notop = VGGFace(model='resnet50', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n",
    "last_layer = vgg_notop.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(4096, activation='relu', name='fc6')(x)\n",
    "x = Dense(1024, activation='relu', name='fc7')(x)\n",
    "#print(\"Emotions count\", len(EMOTIONS))\n",
    "l=0\n",
    "for layer in vgg_notop.layers:\n",
    "    print(layer,\"[\"+str(l)+\"]\")\n",
    "    l=l+1\n",
    "    \n",
    "batch_norm_indices = [2, 6, 9, 13, 14, 18, 21, 24, 28, 31, 34, 38, 41, 45, 46, 53, 56, 60, 63, 66, 70, 73, 76, 80, 83, 87, 88, 92, 95, 98]\n",
    "for i in range(101):\n",
    "    if i not in batch_norm_indices:\n",
    "        vgg_notop.layers[i].trainable = False\n",
    "\n",
    "print('vgg layer 2 is trainable: ' + str(vgg_notop.layers[2].trainable))\n",
    "print('vgg layer 3 is trainable: ' + str(vgg_notop.layers[3].trainable))\n",
    "\n",
    "out = Dense(7, activation='softmax', name='classifier')(x)\n",
    "\n",
    "custom_resnet = Model(vgg_notop.input, out)\n",
    "\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "custom_resnet.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# plot_model(custom_resnet, to_file='model2.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EjKPXZ3TX3Jb",
    "outputId": "ee0e13f9-5570-4876-f3b8-ac0ca4a7818e"
   },
   "outputs": [],
   "source": [
    "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "    # dataset: Data path\n",
    "def get_data(dataset, pixelsize = Resize_pixelsize):\n",
    "    \n",
    "    file_stream = file_io.FileIO(dataset, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "\n",
    "    #data = pd.read_csv('fer2013/fer2013.csv')\n",
    "    data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
    "\n",
    "    # Retrieve train input and target\n",
    "    X, Y = data['pixels'].tolist(), data['emotion'].values\n",
    "    #print(len(X))\n",
    "    #print(X[0])\n",
    "    # Reshape images to 4D (num_samples, width, height, num_channels)\n",
    "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
    "    # Normalize images with max (the maximum pixel intensity is 255)\n",
    "    X = X/255.0\n",
    "    #print(X.shape)\n",
    "    #print(X[0])\n",
    "    #image_resized = resize(image, (image.shape[0] // 4, image.shape[1] // 4), anti_aliasing=True)\n",
    "\n",
    "    X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
    "    for ind in range(X.shape[0]):  #X_dev.shape[0]\n",
    "        sample = X[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        #plt.imshow(sample, cmap='gray')\n",
    "        #plt.show()\n",
    "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
    "        X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
    "    #         np.save('X_res.npy', X_res)\n",
    "\n",
    "    Y_res = np.zeros((Y.size, Y.max()+1))\n",
    "    Y_res[np.arange(Y.size),Y] = 1\n",
    "    \n",
    "    \n",
    "    return  X_res, Y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BS = 32\n",
    "training_dataset_dir = 'fer2013/train.csv'\n",
    "dev_dataset_dir = 'fer2013/dev.csv'\n",
    "# Data preparation\n",
    "X_train_res, Y_train_res  = get_data(training_dataset_dir)\n",
    "X_dev_res, Y_dev_res  = get_data(dev_dataset_dir)\n",
    "\n",
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
    "# rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
    "# rotation_range:   Int. Degree range for random rotations\n",
    "# shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "# zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
    "# fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
    "# horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range  = 10,\n",
    "    shear_range     = 10, # 10 degrees\n",
    "    zoom_range      = 0.1,\n",
    "    fill_mode       = 'reflect',\n",
    "    horizontal_flip = True)\n",
    "\n",
    "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
    "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
    "    #               it should have value 3\n",
    "    # y:            Labels\n",
    "    # batch_size:   Int (default: 32)\n",
    "train_generator = train_datagen.flow(X_train_res, Y_train_res,  batch_size  = BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"X_train shape: \" + str(X_train.shape))\n",
    "#print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "#print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "#print (\"Y_dev shape: \" + str(Y_dev.shape))\n",
    "\n",
    "print (\"X_train_res shape: \" + str(X_train_res.shape))\n",
    "print(\"Y_train_res shape: \" + str(Y_train_res.shape))\n",
    "print (\"X_dev_res shape: \" + str(X_dev_res.shape))\n",
    "print(\"Y_dev_res shape: \" + str(Y_dev_res.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3DpD608HuiQ"
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "#image = X_train[i,:,:,:].reshape(48, 48)\n",
    "#plt.imshow(image, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "image_resized = X_train_res[i,:,:,:].reshape(Resize_pixelsize, Resize_pixelsize, 3)\n",
    "plt.imshow(image_resized)\n",
    "plt.show()\n",
    "print(Y_train_res[i])\n",
    "\n",
    "dev_resized = X_dev_res[i,:,:,:].reshape(Resize_pixelsize, Resize_pixelsize, 3)\n",
    "plt.imshow(dev_resized)\n",
    "plt.show()\n",
    "print(Y_dev_res[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi3lopGhZIuT"
   },
   "source": [
    "#Baseline model\n",
    "model = tf.keras.models.Sequential([\n",
    "    InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
    "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
    "    Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
    "])\n",
    "\n",
    "print(\"Accuracy after training\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKzZuMBafv0a",
    "scrolled": true
   },
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=1, validation_data=(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_x = X_train_res[0:5000]\n",
    "small_y = Y_train_res[0:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLISdlaStbUn"
   },
   "source": [
    "history = custom_resnet.fit(\n",
    "    X_train_res,\n",
    "    Y_train_res,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_dev_res, Y_dev_res)\n",
    ")\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_resnet.fit_generator(\n",
    "    generator           = train_generator,\n",
    "    validation_data=(X_dev_res, Y_dev_res), \n",
    "    steps_per_epoch=len(X_train_res) // BS,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_resnet.save('transfer_learning_DG.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_resnet.evaluate(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_resnet.evaluate(X_dev_res, Y_dev_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "fer2013.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
