{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/saliency/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model\n",
        "import PIL\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "outputId": "d44bbd21-3d24-4cd7-902a-1506e536c146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/My Drive/cs230 project/collab/fer2013/fer2013.csv')\n",
        "\n",
        "#print('Number of samples in the dataset: ', data.shape[0])\n",
        "# Transform images from strings to lists of integers. TODO: use an array cast\n",
        "data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXIX_VLMYJty",
        "colab": {}
      },
      "source": [
        "emotion_cat = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n",
        "\n",
        "# See the target distribution (check for imbalance)\n",
        "#target_counts = data['emotion'].value_counts().reset_index(drop=False)\n",
        "#target_counts.columns = ['emotion', 'number_samples']\n",
        "#target_counts['emotion'] = target_counts['emotion'].map(emotion_cat)\n",
        "#target_counts\n",
        "\n",
        "# Select randomly 10 images\n",
        "#random_seed = 1\n",
        "#data_sample = data.sample(10, random_state=random_seed)\n",
        "#f, axarr = plt.subplots(2, 5, figsize=(20, 10))\n",
        "\n",
        "#i, j = 0, 0\n",
        "#for idx, row in data_sample.iterrows():\n",
        "#    img = np.array(row['pixels']).reshape(48,48)\n",
        "#    axarr[i,j].imshow(img, cmap='gray')\n",
        "#    axarr[i,j].set_title(emotion_cat[row['emotion']])\n",
        "#    if j==4:\n",
        "#        i += 1\n",
        "#        j = 0\n",
        "#    else:\n",
        "#        j += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hAjh6yOLYPZm",
        "colab": {}
      },
      "source": [
        "data_train = data[data['Usage']=='Training']\n",
        "#print('Number samples in the training dataset: ', data_train.shape[0])\n",
        "\n",
        "data_dev = data[data['Usage']=='PublicTest']\n",
        "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
        "\n",
        "# Retrieve train input and target\n",
        "X_train, y_train = data_train['pixels'].tolist(), data_train['emotion'].values\n",
        "# Reshape images to 4D (num_samples, width, height, num_channels)\n",
        "X_train = np.array(X_train, dtype='float32').reshape(-1,48,48,1)\n",
        "# Normalize images with max (the maximum pixel intensity is 255)\n",
        "X_train = X_train/255.0\n",
        "\n",
        "# Retrieve dev input and target\n",
        "X_dev, y_dev = data_dev['pixels'].tolist(), data_dev['emotion'].values\n",
        "X_dev = np.array(X_dev, dtype='float32').reshape(-1,48,48,1)\n",
        "X_dev = X_dev/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yi3lopGhZIuT",
        "outputId": "90bf3984-c679-4097-fcb5-e9c8d9be743e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#Baseline model\n",
        "model = tf.keras.models.Sequential([\n",
        "    InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
        "    Dropout(0.25),\n",
        "    MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
        "    Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
        "])\n",
        "\n",
        "print(\"Accuracy after training\")\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Accuracy after training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iKzZuMBafv0a",
        "scrolled": true,
        "outputId": "e628bb14-c39e-48d3-af4f-c5b7c22b82b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "model.fit(X_train,y_train,batch_size=32,epochs=5,validation_data=(X_dev, y_dev))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/5\n",
            "28709/28709 [==============================] - 17s 603us/sample - loss: 1.7027 - acc: 0.3233 - val_loss: 1.5307 - val_acc: 0.3998\n",
            "Epoch 2/5\n",
            "28709/28709 [==============================] - 11s 385us/sample - loss: 1.4463 - acc: 0.4406 - val_loss: 1.3911 - val_acc: 0.4533\n",
            "Epoch 3/5\n",
            "28709/28709 [==============================] - 11s 385us/sample - loss: 1.2769 - acc: 0.5153 - val_loss: 1.2937 - val_acc: 0.5046\n",
            "Epoch 4/5\n",
            "28709/28709 [==============================] - 11s 382us/sample - loss: 1.0975 - acc: 0.5876 - val_loss: 1.2299 - val_acc: 0.5386\n",
            "Epoch 5/5\n",
            "28709/28709 [==============================] - 11s 382us/sample - loss: 0.8575 - acc: 0.6867 - val_loss: 1.2531 - val_acc: 0.5352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc137f526d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUzRYqVBsOWK",
        "colab_type": "text"
      },
      "source": [
        "# Class activation map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JddX-2mnbzG",
        "colab_type": "code",
        "outputId": "6197500e-3570-4360-e92f-55e18429dd1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "# needed for some newer functions in TF 1.0, e.g. Tensor.numpy()\n",
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |█████████████████████           | 276.1MB 1.4MB/s eta 0:01:47\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 382, in run\n",
            "    resolver.resolve(requirement_set)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 201, in resolve\n",
            "    self._resolve_one(requirement_set, req)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 365, in _resolve_one\n",
            "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 313, in _get_abstract_dist_for\n",
            "    req, self.session, self.finder, self.require_hashes\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/prepare.py\", line 194, in prepare_linked_requirement\n",
            "    progress_bar=self.progress_bar\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 465, in unpack_url\n",
            "    progress_bar=progress_bar\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 316, in unpack_http_url\n",
            "    progress_bar)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 551, in _download_http_url\n",
            "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 253, in _download_url\n",
            "    hashes.check_against_chunks(downloaded_chunks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/hashes.py\", line 80, in check_against_chunks\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 223, in written_chunks\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/ui.py\", line 162, in iter\n",
            "    self.next(n)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 120, in next\n",
            "    self.update()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/bar.py\", line 83, in update\n",
            "    self.writeln(line)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 101, in writeln\n",
            "    self.clearln()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 90, in clearln\n",
            "    print('\\r\\x1b[K', end='', file=self.file)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/ui.py\", line 118, in handle_sigint\n",
            "    self.finish()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/ui.py\", line 108, in finish\n",
            "    super(InterruptibleMixin, self).finish()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 107, in finish\n",
            "    print(file=self.file)\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\u001b[0m\n",
            "\u001b[K"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-25YGdXbslHE",
        "colab_type": "code",
        "outputId": "7039b9ff-e207-42d6-fe44-f035e2f9c2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Select an image to show the saliency map on\n",
        "indx=56\n",
        "plt.title(label = \"class index : {}\".format(emotion_cat[y_dev[indx]]))\n",
        "plt.imshow(X_dev[indx].reshape(48,48),cmap='gray')\n",
        "single_example = X_dev[indx].reshape(1,48,48,1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2kVj-o0lM4t",
        "colab_type": "code",
        "outputId": "11ea5618-09bb-4e88-914a-a9860d4219c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "print(model.weights[-2])\n",
        "weights = model.weights[-2][:,y_dev[indx]]\n",
        "get_conv_layer = Model(inputs=model.input, outputs=model.get_layer(\"conv4\").output)\n",
        "layer_feature_maps = get_conv_layer.predict(single_example)\n",
        "# print(layer_feature_maps)\n",
        "\n",
        "#vectorize\n",
        "cam = 0\n",
        "for k in range(layer_feature_maps.shape[-1]): \n",
        "     cam += weights[k]*layer_feature_maps[:,:,:,k]\n",
        "\n",
        "cam = tf.reshape(cam,[24,24,1])\n",
        "print(cam)\n",
        "cam_resized= tf.image.resize(cam,[48,48])\n",
        "#tf.Session().run(tf.variables_initializer(cam_resized))\n",
        "# TODO: try to replace .numpy() with .eval()\n",
        "plt.imshow(cam_resized.reshape(48,48))\n",
        "plt.figure()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'fc-softmax/kernel:0' shape=(1024, 7) dtype=float32>\n",
            "Tensor(\"Reshape_17:0\", shape=(24, 24, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-992d669be4ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#tf.Session().run(tf.variables_initializer(cam_resized))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# TODO: try to replace .numpy() with .eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWQbfXPNsMRr",
        "colab_type": "text"
      },
      "source": [
        "# Vanilla Gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slI9Li4QsMl-",
        "colab_type": "code",
        "outputId": "d18dceda-e5d7-4196-ede4-7d33f92fde0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        }
      },
      "source": [
        "input_tensors = [model.input]\n",
        "example_model_output = model.output[0][y_dev[indx]]\n",
        "gradients = model.optimizer.get_gradients(example_model_output, model.input)\n",
        "compute_gradients = K.function(inputs = input_tensors, outputs = gradients)\n",
        "\n",
        "gradient_fun  = Model(inputs= model.input, outputs=gradients)\n",
        "gradients_value = gradient_fun(single_example.astype(\"float32\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d78e5165294b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgradient_fun\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgradients_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defun_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:2545 _defun_call  *\n        return self._make_op(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:2523 _make_op\n        c_op = ops._create_c_op(graph, node_def, inputs, control_inputs=[])\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Single tensor passed to 'input', expected list while building NodeDef 'dropout_3/cond' using Op<name=If; signature=cond:Tcond, input: -> output:; attr=Tcond:type; attr=Tin:list(type),min=0; attr=Tout:list(type),min=0; attr=then_branch:func; attr=else_branch:func; attr=output_shapes:list(shape),default=[]; is_stateful=true>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i51rNdXQsWOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}