{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/transfer-learning/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwdg7Sv3XBaP"
   },
   "outputs": [],
   "source": [
    "#tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nz38mJZXN_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import *\n",
    "from keras.engine import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "\n",
    "import pydot\n",
    "\n",
    "!python -c \"import skimage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try:\n",
    "    pydot.Dot.create(pydot.Dot())\n",
    "except:\n",
    "    print('pydot error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nUcd6yIGduUW",
    "outputId": "94e06002-1afb-4fab-b6fc-f69cef85fa1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EarfWgg_Y4rR",
    "outputId": "a053f8b0-3c50-46bd-abc3-19e52a91aed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Building CNN\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f6f8e30aa20> [0]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8e30ac50> [1]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8e30ae10> [2]\n",
      "<keras.layers.core.Activation object at 0x7f6f8e30aef0> [3]\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6f8c0d3f28> [4]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8c0e8c88> [5]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8c0f7e48> [6]\n",
      "<keras.layers.core.Activation object at 0x7f6f8c0f7ef0> [7]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8c082c88> [8]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8c0b5940> [9]\n",
      "<keras.layers.core.Activation object at 0x7f6f8c0b58d0> [10]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8c042e48> [11]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8c080828> [12]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8c080278> [13]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8c03fa20> [14]\n",
      "<keras.layers.merge.Add object at 0x7f6f8c03fac8> [15]\n",
      "<keras.layers.core.Activation object at 0x7f6f844fdfd0> [16]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8450a438> [17]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f844a6cf8> [18]\n",
      "<keras.layers.core.Activation object at 0x7f6f844afe80> [19]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f844aff98> [20]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f84467d30> [21]\n",
      "<keras.layers.core.Activation object at 0x7f6f8446ff28> [22]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84477a20> [23]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f844307b8> [24]\n",
      "<keras.layers.merge.Add object at 0x7f6f84430748> [25]\n",
      "<keras.layers.core.Activation object at 0x7f6f8444ff98> [26]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8445b3c8> [27]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f843f9c88> [28]\n",
      "<keras.layers.core.Activation object at 0x7f6f843f9f98> [29]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84400f60> [30]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f843b8c88> [31]\n",
      "<keras.layers.core.Activation object at 0x7f6f843bff60> [32]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f843c6978> [33]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8437e710> [34]\n",
      "<keras.layers.merge.Add object at 0x7f6f8437e6a0> [35]\n",
      "<keras.layers.core.Activation object at 0x7f6f84329358> [36]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84330f60> [37]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8433db38> [38]\n",
      "<keras.layers.core.Activation object at 0x7f6f8433de48> [39]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84346e48> [40]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f842fcb38> [41]\n",
      "<keras.layers.core.Activation object at 0x7f6f84300e10> [42]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84300c18> [43]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f842c4518> [44]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f842c4588> [45]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f84286e48> [46]\n",
      "<keras.layers.merge.Add object at 0x7f6f8428bfd0> [47]\n",
      "<keras.layers.core.Activation object at 0x7f6f84222f28> [48]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84229c50> [49]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8424dcf8> [50]\n",
      "<keras.layers.core.Activation object at 0x7f6f84254d68> [51]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84254da0> [52]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f84215278> [53]\n",
      "<keras.layers.core.Activation object at 0x7f6f84215898> [54]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8421ce80> [55]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f841d5b70> [56]\n",
      "<keras.layers.merge.Add object at 0x7f6f841dbe48> [57]\n",
      "<keras.layers.core.Activation object at 0x7f6f84171fd0> [58]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f8418e6d8> [59]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8419cfd0> [60]\n",
      "<keras.layers.core.Activation object at 0x7f6f84125cf8> [61]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84125f60> [62]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f840e51d0> [63]\n",
      "<keras.layers.core.Activation object at 0x7f6f840e57f0> [64]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f840ecdd8> [65]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f840a4ac8> [66]\n",
      "<keras.layers.merge.Add object at 0x7f6f840abda0> [67]\n",
      "<keras.layers.core.Activation object at 0x7f6f840c1f98> [68]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f840dc630> [69]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f8406af28> [70]\n",
      "<keras.layers.core.Activation object at 0x7f6f84073c50> [71]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84073eb8> [72]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f84031128> [73]\n",
      "<keras.layers.core.Activation object at 0x7f6f84031748> [74]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f84039d30> [75]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c65aa20> [76]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c65af98> [77]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c676fd0> [78]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c614588> [79]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c623f60> [80]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c62add8> [81]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c62af60> [82]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c5e2fd0> [83]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c5e9668> [84]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c5f3c50> [85]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c5ab978> [86]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c5ab9e8> [87]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c5719e8> [88]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c571a90> [89]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c50bfd0> [90]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c529668> [91]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c537f98> [92]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c53dd68> [93]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c53db70> [94]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c4ff518> [95]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c4ff4a8> [96]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c489f60> [97]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c4c0e10> [98]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c446f60> [99]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c45bd68> [100]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c463eb8> [101]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c40eac8> [102]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c40edd8> [103]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c41add8> [104]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c3d1ac8> [105]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c3d8da0> [106]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c3d8ba8> [107]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c398550> [108]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c3984e0> [109]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c3afa90> [110]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c3afc50> [111]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c35ecc0> [112]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c366d30> [113]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c366f98> [114]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c329208> [115]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c3297f0> [116]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c32fdd8> [117]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c2eaac8> [118]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c2efda0> [119]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c285f60> [120]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c28cb70> [121]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c2b77b8> [122]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c2b7fd0> [123]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c2c0ac8> [124]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c277860> [125]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c2777f0> [126]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c27ffd0> [127]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c23c240> [128]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c23c860> [129]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c1d0ac8> [130]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c1ccf60> [131]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c1f7e10> [132]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c201e10> [133]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c201f60> [134]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c1b8e10> [135]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c1c2f60> [136]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c149b00> [137]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c17f898> [138]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c17f828> [139]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c115a58> [140]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c1396d8> [141]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c0c6ef0> [142]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c0cdda0> [143]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c0cdba8> [144]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c08d550> [145]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c08d4e0> [146]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c095f98> [147]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c055f98> [148]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c04fe48> [149]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f7c017e80> [150]\n",
      "<keras.layers.merge.Add object at 0x7f6f7c01ddd8> [151]\n",
      "<keras.layers.core.Activation object at 0x7f6f7c036f98> [152]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f7c03ccc0> [153]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f3c1d9908> [154]\n",
      "<keras.layers.core.Activation object at 0x7f6f3c1d9f28> [155]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f3c1e3c50> [156]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f3c19c9e8> [157]\n",
      "<keras.layers.core.Activation object at 0x7f6f3c19c978> [158]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f3c1a5ef0> [159]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f3c1613c8> [160]\n",
      "<keras.layers.merge.Add object at 0x7f6f3c1619e8> [161]\n",
      "<keras.layers.core.Activation object at 0x7f6f3c0fa908> [162]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f3c0faf60> [163]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f3c12af98> [164]\n",
      "<keras.layers.core.Activation object at 0x7f6f3c133e10> [165]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f3c133f98> [166]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f3c0eaf60> [167]\n",
      "<keras.layers.core.Activation object at 0x7f6f3c0f36a0> [168]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6f3c07cc88> [169]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6f3c0b2a20> [170]\n",
      "<keras.layers.merge.Add object at 0x7f6f3c0b29b0> [171]\n",
      "<keras.layers.core.Activation object at 0x7f6f3c04bf60> [172]\n",
      "<keras.layers.pooling.AveragePooling2D object at 0x7f6f3c0589e8> [173]\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x7f6efeca2908> [174]\n",
      "vgg layer 2 is trainable: True\n",
      "vgg layer 3 is trainable: False\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('[+] Building CNN')\n",
    "\n",
    "vgg_notop = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "last_layer = vgg_notop.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(4096, activation='relu', name='fc6')(x)\n",
    "x = Dense(1024, activation='relu', name='fc7')(x)\n",
    "#print(\"Emotions count\", len(EMOTIONS))\n",
    "l=0\n",
    "for layer in vgg_notop.layers:\n",
    "    print(layer,\"[\"+str(l)+\"]\")\n",
    "    l=l+1\n",
    "    \n",
    "batch_norm_indices = [2, 6, 9, 13, 14, 18, 21, 24, 28, 31, 34, 38, 41, 45, 46, 53, 56, 60, 63, 66, 70, 73, 76, 80, 83, 87, 88, 92, 95, 98]\n",
    "for i in range(101):\n",
    "    if i not in batch_norm_indices:\n",
    "        vgg_notop.layers[i].trainable = False\n",
    "\n",
    "print('vgg layer 2 is trainable: ' + str(vgg_notop.layers[2].trainable))\n",
    "print('vgg layer 3 is trainable: ' + str(vgg_notop.layers[3].trainable))\n",
    "\n",
    "out = Dense(7, activation='softmax', name='classifier')(x)\n",
    "\n",
    "custom_resnet = Model(vgg_notop.input, out)\n",
    "\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "custom_resnet.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_model(custom_resnet, to_file='model2.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EjKPXZ3TX3Jb",
    "outputId": "ee0e13f9-5570-4876-f3b8-ac0ca4a7818e"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013/fer2013.csv')\n",
    "data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    X_train_res = np.load('X_train_res.npy')\n",
    "    X_dev_res = np.load('X_dev_res.npy')\n",
    "except:\n",
    "    print('No file found')\n",
    "    X_train_res = None\n",
    "    X_dev_res = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAjh6yOLYPZm"
   },
   "outputs": [],
   "source": [
    "if X_train_res is None:\n",
    "    data_train = data[data['Usage'] == 'Training']\n",
    "    #print('Number samples in the training dataset: ', data_train.shape[0])\n",
    "\n",
    "    data_dev = data[data['Usage'] == 'PublicTest']\n",
    "    #print('Number samples in the development dataset: ', data_dev.shape[0])\n",
    "\n",
    "    # Retrieve train input and target\n",
    "    X_train, Y_train = data_train['pixels'].tolist(), data_train['emotion'].values\n",
    "    #print(len(X_train))\n",
    "    #print(X_train[0])\n",
    "    # Reshape images to 4D (num_samples, width, height, num_channels)\n",
    "    X_train = np.array(X_train, dtype='float32').reshape(-1,48,48,1)\n",
    "    # Normalize images with max (the maximum pixel intensity is 255)\n",
    "    X_train = X_train/255.0\n",
    "    #print(X_train.shape)\n",
    "    #print(X_train[0])\n",
    "    #image_resized = resize(image, (image.shape[0] // 4, image.shape[1] // 4), anti_aliasing=True)\n",
    "\n",
    "    # Retrieve dev input and target\n",
    "    X_dev, Y_dev = data_dev['pixels'].tolist(), data_dev['emotion'].values\n",
    "    X_dev = np.array(X_dev, dtype='float32').reshape(-1,48,48,1)\n",
    "    X_dev = X_dev/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXi9lYtSHbq3"
   },
   "outputs": [],
   "source": [
    "pixelsize = 224\n",
    "if X_dev_res is None:\n",
    "    X_dev_res = np.zeros((X_dev.shape[0], pixelsize,pixelsize,3))\n",
    "    for ind in range(X_dev.shape[0]):  #X_dev.shape[0]\n",
    "        sample = X_dev[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        #plt.imshow(sample, cmap='gray')\n",
    "        #plt.show()\n",
    "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
    "        X_dev_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
    "#         np.save('X_dev_res.npy', X_dev_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msnO_J1VPyLa"
   },
   "outputs": [],
   "source": [
    "if X_train_res is None:\n",
    "    X_train_res = np.zeros((X_train.shape[0], pixelsize,pixelsize,3))\n",
    "    for ind in range(X_train.shape[0]):  #X_dev.shape[0]\n",
    "        sample = X_train[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        #plt.imshow(sample, cmap='gray')\n",
    "        #plt.show()\n",
    "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
    "        X_train_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
    "#         np.save('X_train_res.npy', X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_res = np.zeros((Y_train.size, Y_train.max()+1))\n",
    "Y_train_res[np.arange(Y_train.size),Y_train] = 1\n",
    "Y_dev_res = np.zeros((Y_dev.size, Y_dev.max()+1))\n",
    "Y_dev_res[np.arange(Y_dev.size),Y_dev] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(Y_dev.shape))\n",
    "\n",
    "print (\"X_train_res shape: \" + str(X_train_res.shape))\n",
    "print(\"Y_train_res shape: \" + str(Y_train_res.shape))\n",
    "print (\"X_dev_res shape: \" + str(X_dev_res.shape))\n",
    "print(\"Y_dev_res shape: \" + str(Y_dev_res.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3DpD608HuiQ"
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "image = X_train[i,:,:,:].reshape(48, 48)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "image_resized = X_train_res[i,:,:,:].reshape(pixelsize, pixelsize, 3)\n",
    "plt.imshow(image_resized)\n",
    "plt.show()\n",
    "print(Y_train_res[i])\n",
    "\n",
    "dev_resized = X_dev_res[i,:,:,:].reshape(pixelsize, pixelsize, 3)\n",
    "plt.imshow(dev_resized)\n",
    "plt.show()\n",
    "print(Y_dev_res[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SktuGWC4Kkob"
   },
   "outputs": [],
   "source": [
    "print(sample.shape)\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi3lopGhZIuT"
   },
   "source": [
    "#Baseline model\n",
    "model = tf.keras.models.Sequential([\n",
    "    InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
    "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
    "    Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
    "])\n",
    "\n",
    "print(\"Accuracy after training\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKzZuMBafv0a",
    "scrolled": true
   },
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=1, validation_data=(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_x = X_train_res[0:5000]\n",
    "small_y = Y_train_res[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLISdlaStbUn"
   },
   "outputs": [],
   "source": [
    "history = custom_resnet.fit(\n",
    "    X_train_res,\n",
    "    Y_train_res,\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_dev_res, Y_dev_res)\n",
    ")\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_resnet.evaluate(X_dev_res, Y_dev_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SULdLnQ5uAwD",
    "outputId": "a3fa4653-90c7-4c85-c058-fb8a7b0012bf"
   },
   "outputs": [],
   "source": [
    "custom_resnet.predict(X_dev_res[0].reshape(1, 224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iD5SU3RMaTR3"
   },
   "outputs": [],
   "source": [
    "Y_dev_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_resnet.predict(X_train_res[0].reshape(1, 224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_resnet.predict(X_train_res[1].reshape(1, 224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "fer2013.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
