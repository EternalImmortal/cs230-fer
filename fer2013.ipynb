{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/master/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "outputId": "7e1140f2-c1f7-403d-f04d-17efdc4ecfc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/My Drive/cs230 project/collab/fer2013/fer2013.csv')\n",
        "\n",
        "#print('Number of samples in the dataset: ', data.shape[0])\n",
        "# Transform images from strings to lists of integers. TODO: use an array cast\n",
        "data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXIX_VLMYJty",
        "colab": {}
      },
      "source": [
        "emotion_cat = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}\n",
        "\n",
        "# See the target distribution (check for imbalance)\n",
        "#target_counts = data['emotion'].value_counts().reset_index(drop=False)\n",
        "#target_counts.columns = ['emotion', 'number_samples']\n",
        "#target_counts['emotion'] = target_counts['emotion'].map(emotion_cat)\n",
        "#target_counts\n",
        "\n",
        "# Select randomly 10 images\n",
        "#random_seed = 1\n",
        "#data_sample = data.sample(10, random_state=random_seed)\n",
        "#f, axarr = plt.subplots(2, 5, figsize=(20, 10))\n",
        "\n",
        "#i, j = 0, 0\n",
        "#for idx, row in data_sample.iterrows():\n",
        "#    img = np.array(row['pixels']).reshape(48,48)\n",
        "#    axarr[i,j].imshow(img, cmap='gray')\n",
        "#    axarr[i,j].set_title(emotion_cat[row['emotion']])\n",
        "#    if j==4:\n",
        "#        i += 1\n",
        "#        j = 0\n",
        "#    else:\n",
        "#        j += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hAjh6yOLYPZm",
        "colab": {}
      },
      "source": [
        "data_train = data[data['Usage']=='Training']\n",
        "#print('Number samples in the training dataset: ', data_train.shape[0])\n",
        "\n",
        "data_dev = data[data['Usage']=='PublicTest']\n",
        "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
        "\n",
        "# Retrieve train input and target\n",
        "X_train, y_train = data_train['pixels'].tolist(), data_train['emotion'].values\n",
        "# Reshape images to 4D (num_samples, width, height, num_channels)\n",
        "X_train = np.array(X_train, dtype='float32').reshape(-1,48,48,1)\n",
        "# Normalize images with max (the maximum pixel intensity is 255)\n",
        "X_train = X_train/255.0\n",
        "\n",
        "# Retrieve dev input and target\n",
        "X_dev, y_dev = data_dev['pixels'].tolist(), data_dev['emotion'].values\n",
        "X_dev = np.array(X_dev, dtype='float32').reshape(-1,48,48,1)\n",
        "X_dev = X_dev/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yi3lopGhZIuT",
        "outputId": "81a73ee2-e992-465c-9e04-81bf304c1307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Baseline model\n",
        "model = tf.keras.models.Sequential([\n",
        "    InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
        "    Dropout(0.25), BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
        "    Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
        "])\n",
        "\n",
        "print(\"Accuracy after training\")\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iKzZuMBafv0a",
        "scrolled": true,
        "outputId": "1c16e38c-cd0e-4768-d560-606d611f8393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model.fit(X_train,y_train,batch_size=32,epochs=1,validation_data=(X_dev, y_dev))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "28709/28709 [==============================] - 18s 615us/sample - loss: 1.6775 - accuracy: 0.3583 - val_loss: 1.5534 - val_accuracy: 0.3901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe5b5dc0cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}