{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/master/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVbLZURCveTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "outputId": "e48210cc-ef44-4ddb-928c-a3cdb1a769e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/My Drive/cs230 project/collab/fer2013/fer2013.csv')\n",
        "\n",
        "#print('Number of samples in the dataset: ', data.shape[0])\n",
        "# Transform images from strings to lists of integers. TODO: use an array cast\n",
        "data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXIX_VLMYJty",
        "colab": {}
      },
      "source": [
        "emotion_cat = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hAjh6yOLYPZm",
        "colab": {}
      },
      "source": [
        "data_train = data[data['Usage']=='Training']\n",
        "#print('Number samples in the training dataset: ', data_train.shape[0])\n",
        "\n",
        "data_dev = data[data['Usage']=='PublicTest']\n",
        "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
        "\n",
        "# Retrieve train input and target\n",
        "X_train, y_train = data_train['pixels'].tolist(), data_train['emotion'].values\n",
        "# Reshape images to 4D (num_samples, width, height, num_channels)\n",
        "X_train = np.array(X_train, dtype='float32').reshape(-1,48,48,1)\n",
        "# Normalize images with max (the maximum pixel intensity is 255)\n",
        "X_train = X_train/255.0\n",
        "\n",
        "# Retrieve dev input and target\n",
        "X_dev, y_dev = data_dev['pixels'].tolist(), data_dev['emotion'].values\n",
        "X_dev = np.array(X_dev, dtype='float32').reshape(-1,48,48,1)\n",
        "X_dev = X_dev/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yi3lopGhZIuT",
        "colab": {}
      },
      "source": [
        "#Baseline model\n",
        "model = tf.keras.models.Sequential([\n",
        "    InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
        "    Dropout(0.25),\n",
        "    MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
        "    Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iKzZuMBafv0a",
        "scrolled": true,
        "outputId": "90e5009a-8541-4eb6-b3ca-068934ceaa61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "model.fit(X_train,y_train,batch_size=32,epochs=5,validation_data=(X_dev, y_dev))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/5\n",
            "28709/28709 [==============================] - 26s 897us/sample - loss: 0.5994 - acc: 0.7847 - val_loss: 1.3848 - val_acc: 0.5311\n",
            "Epoch 2/5\n",
            "28709/28709 [==============================] - 26s 896us/sample - loss: 0.3668 - acc: 0.8747 - val_loss: 1.5980 - val_acc: 0.5308\n",
            "Epoch 3/5\n",
            "28709/28709 [==============================] - 26s 891us/sample - loss: 0.2380 - acc: 0.9213 - val_loss: 1.7969 - val_acc: 0.5216\n",
            "Epoch 4/5\n",
            "28709/28709 [==============================] - 26s 891us/sample - loss: 0.1849 - acc: 0.9428 - val_loss: 2.0679 - val_acc: 0.5130\n",
            "Epoch 5/5\n",
            "28709/28709 [==============================] - 26s 889us/sample - loss: 0.1480 - acc: 0.9549 - val_loss: 2.1488 - val_acc: 0.5074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff210dcdba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkkxgoSy1Ot_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a879860-e62d-44d6-e26d-d746682a3e50"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/cs230 project/webcam images',\n",
        "        target_size=(48, 48),\n",
        "        color_mode='grayscale',\n",
        "        shuffle = False,\n",
        "        class_mode='categorical',\n",
        "        batch_size=1)\n",
        "\n",
        "nb_samples = len(test_generator.filenames)\n",
        "\n",
        "y_true = test_generator.classes\n",
        "#evaluate_generator\n",
        "y_pred = model.predict_generator(test_generator, steps=nb_samples).argmax(axis=1)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 84 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZMRafd0Cl0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c1245ec5-cc25-40d9-fb9a-5379406e8897"
      },
      "source": [
        "y_true-y_pred"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6, -6, -6, -2, -2, -6, -4,  0, -2, -2, -2, -6, -6, -6, -4, -6, -6,\n",
              "       -3, -6, -6, -3, -5,  1, -2, -3, -3, -3,  1, -1,  1, -3, -3, -5, -3,\n",
              "       -5, -3, -5, -3, -3, -5, -5, -5, -5, -5, -5, -2, -3,  1, -5, -2,  0,\n",
              "        0,  0,  0,  0, -3,  0,  0,  0,  0, -3,  1, -1,  0,  0,  0,  0,  2,\n",
              "       -2, -2, -2, -2,  2,  2,  2,  2,  2,  0,  0,  3,  0,  0,  0,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz7UpuRZDGxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef1913aa-6070-4197-e6b3-f615b83e6fe4"
      },
      "source": [
        "test_generator.filenames[0]"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0 angry/angry0000.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltHJVttzFT3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}