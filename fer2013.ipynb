{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/transfer-learning/fer2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwdg7Sv3XBaP"
   },
   "outputs": [],
   "source": [
    "#tensorflow_version 1.x\n",
    "#!pip install keras-vggface\n",
    "#!conda install scikit-image\n",
    "#!conda install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nz38mJZXN_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import *\n",
    "from keras.engine import Model\n",
    "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "from skimage.transform import rescale, resize\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -c \"import skimage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pydot.Dot.create(pydot.Dot())\n",
    "except:\n",
    "    print('pydot error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nUcd6yIGduUW",
    "outputId": "94e06002-1afb-4fab-b6fc-f69cef85fa1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.read_csv('fer2013/fer2013.csv')\n",
    "data.head()\n",
    "\n",
    "data_train = data[data['Usage'] == 'Training']\n",
    "#print('Number samples in the training dataset: ', data_train.shape[0])\n",
    "\n",
    "data_dev = data[data['Usage'] == 'PublicTest']\n",
    "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
    "data_dev.head()\n",
    "\n",
    "data_train.to_csv('fer2013/train.csv')\n",
    "data_dev.to_csv('fer2013/dev.csv')\n",
    "\n",
    "print(data_train.shape)\n",
    "\n",
    "print(data_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.read_csv('fer2013/icml_face_data.csv') \n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "print(data[' Usage'].unique())\n",
    "\n",
    "data_dev2 = data[data[' Usage'] == 'PublicTest']\n",
    "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
    "print(data_dev2.head())\n",
    "\n",
    "data_dev2.to_csv('fer2013/dev2.csv')\n",
    "print(data_dev2.shape)\n",
    "\n",
    "data_test = data[data[' Usage'] == 'PrivateTest']\n",
    "#print('Number samples in the development dataset: ', data_dev.shape[0])\n",
    "print(data_test.head())\n",
    "\n",
    "data_test.to_csv('fer2013/test.csv')\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCHS = 1\n",
    "BS = 128\n",
    "DROPOUT_RATE = 0.5\n",
    "FROZEN_LAYER_NUM = 160\n",
    "\n",
    "ADAM_LEARNING_RATE=0.001\n",
    "SGD_LEARNING_RATE=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EarfWgg_Y4rR",
    "outputId": "a053f8b0-3c50-46bd-abc3-19e52a91aed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f23dc94f4e0> [0]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23dc94f940> [1]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23dc94fba8> [2]\n",
      "<keras.layers.core.Activation object at 0x7f24189960b8> [3]\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f23dc986f98> [4]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23dc122eb8> [5]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23dc0c6c18> [6]\n",
      "<keras.layers.core.Activation object at 0x7f23dc0c6f28> [7]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23dc0cf908> [8]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23dc0895f8> [9]\n",
      "<keras.layers.core.Activation object at 0x7f23dc089588> [10]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23dc091ef0> [11]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23dc048fd0> [12]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23dce15dd8> [13]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d42fa630> [14]\n",
      "<keras.layers.merge.Add object at 0x7f23d42fad30> [15]\n",
      "<keras.layers.core.Activation object at 0x7f23d43139b0> [16]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d4313fd0> [17]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d42c6860> [18]\n",
      "<keras.layers.core.Activation object at 0x7f23d42c6fd0> [19]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d42cdb70> [20]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d4286860> [21]\n",
      "<keras.layers.core.Activation object at 0x7f23d42867f0> [22]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d428efd0> [23]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d424e198> [24]\n",
      "<keras.layers.merge.Add object at 0x7f23d424e780> [25]\n",
      "<keras.layers.core.Activation object at 0x7f23d42646a0> [26]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d4264f60> [27]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d420ee80> [28]\n",
      "<keras.layers.core.Activation object at 0x7f23d4218e48> [29]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d4218f60> [30]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d41d8518> [31]\n",
      "<keras.layers.core.Activation object at 0x7f23d41d84a8> [32]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d41dff60> [33]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d4194d30> [34]\n",
      "<keras.layers.merge.Add object at 0x7f23d419ef28> [35]\n",
      "<keras.layers.core.Activation object at 0x7f23d4146eb8> [36]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d4141940> [37]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d4157cc0> [38]\n",
      "<keras.layers.core.Activation object at 0x7f23d415dd30> [39]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d415df98> [40]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d411c128> [41]\n",
      "<keras.layers.core.Activation object at 0x7f23d411c748> [42]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d4123cf8> [43]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d40db978> [44]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d40db9e8> [45]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d40a31d0> [46]\n",
      "<keras.layers.merge.Add object at 0x7f23d40a3fd0> [47]\n",
      "<keras.layers.core.Activation object at 0x7f23d403ae80> [48]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d4040f98> [49]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23d404ef60> [50]\n",
      "<keras.layers.core.Activation object at 0x7f23d406cb38> [51]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23d406cef0> [52]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4680400> [53]\n",
      "<keras.layers.core.Activation object at 0x7f23b4680a20> [54]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4609e48> [55]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4641c18> [56]\n",
      "<keras.layers.merge.Add object at 0x7f23b45c8ef0> [57]\n",
      "<keras.layers.core.Activation object at 0x7f23b45ddf28> [58]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b45f96a0> [59]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4588f98> [60]\n",
      "<keras.layers.core.Activation object at 0x7f23b4592cc0> [61]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4592f28> [62]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b454bf28> [63]\n",
      "<keras.layers.core.Activation object at 0x7f23b45516d8> [64]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4559c88> [65]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4511978> [66]\n",
      "<keras.layers.merge.Add object at 0x7f23b4511908> [67]\n",
      "<keras.layers.core.Activation object at 0x7f23b4528a90> [68]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b44cb358> [69]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b44dad68> [70]\n",
      "<keras.layers.core.Activation object at 0x7f23b44daf60> [71]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b44e4eb8> [72]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b449dc88> [73]\n",
      "<keras.layers.core.Activation object at 0x7f23b44a1f60> [74]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b44a9940> [75]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4462630> [76]\n",
      "<keras.layers.merge.Add object at 0x7f23b44625c0> [77]\n",
      "<keras.layers.core.Activation object at 0x7f23b4478b70> [78]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4478cf8> [79]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b442da20> [80]\n",
      "<keras.layers.core.Activation object at 0x7f23b442dd30> [81]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4435cf8> [82]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b43ed9e8> [83]\n",
      "<keras.layers.core.Activation object at 0x7f23b43ed978> [84]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b43f4ef0> [85]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b43b5908> [86]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b43b52e8> [87]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b437b1d0> [88]\n",
      "<keras.layers.merge.Add object at 0x7f23b437bfd0> [89]\n",
      "<keras.layers.core.Activation object at 0x7f23b430fe80> [90]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4317f98> [91]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4342b00> [92]\n",
      "<keras.layers.core.Activation object at 0x7f23b4342e80> [93]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b42cce10> [94]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4286a58> [95]\n",
      "<keras.layers.core.Activation object at 0x7f23b428db38> [96]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b428def0> [97]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b424b400> [98]\n",
      "<keras.layers.merge.Add object at 0x7f23b424ba20> [99]\n",
      "<keras.layers.core.Activation object at 0x7f23b425f940> [100]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b425ff60> [101]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4213ef0> [102]\n",
      "<keras.layers.core.Activation object at 0x7f23b421cd68> [103]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b421cef0> [104]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b41d6e10> [105]\n",
      "<keras.layers.core.Activation object at 0x7f23b41ddf60> [106]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b41e6ac8> [107]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b419f7b8> [108]\n",
      "<keras.layers.merge.Add object at 0x7f23b419f748> [109]\n",
      "<keras.layers.core.Activation object at 0x7f23b41b48d0> [110]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4156518> [111]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b4166eb8> [112]\n",
      "<keras.layers.core.Activation object at 0x7f23b416ce80> [113]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b416ceb8> [114]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b412d2b0> [115]\n",
      "<keras.layers.core.Activation object at 0x7f23b412d8d0> [116]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4135e80> [117]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b40efac8> [118]\n",
      "<keras.layers.merge.Add object at 0x7f23b40f5da0> [119]\n",
      "<keras.layers.core.Activation object at 0x7f23b408cf98> [120]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4092b00> [121]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b40bf6a0> [122]\n",
      "<keras.layers.core.Activation object at 0x7f23b40bff98> [123]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4047978> [124]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b407e668> [125]\n",
      "<keras.layers.core.Activation object at 0x7f23b407e5f8> [126]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23b4006f60> [127]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23b40363c8> [128]\n",
      "<keras.layers.merge.Add object at 0x7f23b40369e8> [129]\n",
      "<keras.layers.core.Activation object at 0x7f23a41be908> [130]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23a41bef60> [131]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23a41ecf98> [132]\n",
      "<keras.layers.core.Activation object at 0x7f23a41f6e10> [133]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23a41f6f98> [134]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23a41aef60> [135]\n",
      "<keras.layers.core.Activation object at 0x7f23a41b56a0> [136]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23a4141c50> [137]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23a4175a20> [138]\n",
      "<keras.layers.merge.Add object at 0x7f23a41759b0> [139]\n",
      "<keras.layers.core.Activation object at 0x7f23a410ef60> [140]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23a411e9e8> [141]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23a40c4630> [142]\n",
      "<keras.layers.core.Activation object at 0x7f23a40c4f28> [143]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23a40cd908> [144]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23a40876d8> [145]\n",
      "<keras.layers.core.Activation object at 0x7f23a4087668> [146]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23a408efd0> [147]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23a404e6d8> [148]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23a4047f28> [149]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23805740b8> [150]\n",
      "<keras.layers.merge.Add object at 0x7f2380574f98> [151]\n",
      "<keras.layers.core.Activation object at 0x7f238058ed30> [152]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f2380592e48> [153]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f238053ca90> [154]\n",
      "<keras.layers.core.Activation object at 0x7f238053ce10> [155]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f2380546da0> [156]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23804feac8> [157]\n",
      "<keras.layers.core.Activation object at 0x7f2380504da0> [158]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f2380504ba8> [159]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f23804c4550> [160]\n",
      "<keras.layers.merge.Add object at 0x7f23804c44e0> [161]\n",
      "<keras.layers.core.Activation object at 0x7f238045ca90> [162]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f238045cc50> [163]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f238048ccc0> [164]\n",
      "<keras.layers.core.Activation object at 0x7f2380496d30> [165]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f2380496f98> [166]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f2380456208> [167]\n",
      "<keras.layers.core.Activation object at 0x7f2380456828> [168]\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f23803dcdd8> [169]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f2380411b00> [170]\n",
      "<keras.layers.merge.Add object at 0x7f238039bdd8> [171]\n",
      "<keras.layers.core.Activation object at 0x7f23803aaf60> [172]\n",
      "<keras.layers.pooling.AveragePooling2D object at 0x7f23803b7b70> [173]\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x7f238035ea90> [174]\n",
      "vgg layer 2 is trainable: True\n",
      "vgg layer 3 is trainable: False\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Resize_pixelsize = 197\n",
    "\n",
    "vgg_notop = VGGFace(model='resnet50', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n",
    "last_layer = vgg_notop.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(4096, activation='relu', name='fc6')(x)\n",
    "x = Dense(1024, activation='relu', name='fc7')(x)\n",
    "#print(\"Emotions count\", len(EMOTIONS))\n",
    "l=0\n",
    "for layer in vgg_notop.layers:\n",
    "    print(layer,\"[\"+str(l)+\"]\")\n",
    "    l=l+1\n",
    "    \n",
    "batch_norm_indices = [2, 6, 9, 13, 14, 18, 21, 24, 28, 31, 34, 38, 41, 45, 46, 53, 56, 60, 63, 66, 70, 73, 76, 80, 83, 87, 88, 92, 95, 98]\n",
    "for i in range(101):\n",
    "    if i not in batch_norm_indices:\n",
    "        vgg_notop.layers[i].trainable = False\n",
    "\n",
    "print('vgg layer 2 is trainable: ' + str(vgg_notop.layers[2].trainable))\n",
    "print('vgg layer 3 is trainable: ' + str(vgg_notop.layers[3].trainable))\n",
    "\n",
    "out = Dense(7, activation='softmax', name='classifier')(x)\n",
    "\n",
    "custom_resnet = Model(vgg_notop.input, out)\n",
    "\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "custom_resnet.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_model(custom_resnet, to_file='model2.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EjKPXZ3TX3Jb",
    "outputId": "ee0e13f9-5570-4876-f3b8-ac0ca4a7818e"
   },
   "source": [
    "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "    # dataset: Data path\n",
    "def get_data(dataset, pixelsize = Resize_pixelsize):\n",
    "    \n",
    "    file_stream = file_io.FileIO(dataset, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "\n",
    "    #data = pd.read_csv('fer2013/fer2013.csv')\n",
    "    data['pixels'] = data['pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
    "\n",
    "    # Retrieve train input and target\n",
    "    X, Y = data['pixels'].tolist(), data['emotion'].values\n",
    "    #print(len(X))\n",
    "    #print(X[0])\n",
    "    # Reshape images to 4D (num_samples, width, height, num_channels)\n",
    "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
    "    # Normalize images with max (the maximum pixel intensity is 255)\n",
    "    X = X/255.0\n",
    "    #print(X.shape)\n",
    "    #print(X[0])\n",
    "    #image_resized = resize(image, (image.shape[0] // 4, image.shape[1] // 4), anti_aliasing=True)\n",
    "\n",
    "    X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
    "    for ind in range(X.shape[0]):  #X_dev.shape[0]\n",
    "        sample = X[ind]\n",
    "        sample = sample.reshape(48, 48)\n",
    "        #plt.imshow(sample, cmap='gray')\n",
    "        #plt.show()\n",
    "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
    "        X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
    "    #         np.save('X_res.npy', X_res)\n",
    "\n",
    "    Y_res = np.zeros((Y.size, Y.max()+1))\n",
    "    Y_res[np.arange(Y.size),Y] = 1\n",
    "    \n",
    "    \n",
    "    return  X_res, Y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCHS = 20\n",
    "BS = 32\n",
    "training_dataset_dir = 'fer2013/train.csv'\n",
    "dev_dataset_dir = 'fer2013/dev.csv'\n",
    "# Data preparation\n",
    "X_train_res, Y_train_res  = get_data(training_dataset_dir)\n",
    "X_dev_res, Y_dev_res  = get_data(dev_dataset_dir)\n",
    "\n",
    "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
    "# rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
    "# rotation_range:   Int. Degree range for random rotations\n",
    "# shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "# zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
    "# fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
    "# horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range  = 10,\n",
    "    shear_range     = 10, # 10 degrees\n",
    "    zoom_range      = 0.1,\n",
    "    fill_mode       = 'reflect',\n",
    "    horizontal_flip = True)\n",
    "\n",
    "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
    "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
    "    #               it should have value 3\n",
    "    # y:            Labels\n",
    "    # batch_size:   Int (default: 32)\n",
    "train_generator = train_datagen.flow(X_train_res, Y_train_res,  batch_size  = BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE FIRST LINE IS SKIPPED\n",
      "(6, 197, 197, 3)\n",
      "(6, 7)\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "pixelsize = 197\n",
    "image_reshaped = np.zeros((pixelsize,pixelsize,3))\n",
    "\n",
    "f = open('fer2013/train.csv', \"r\")\n",
    "\n",
    "images=[]\n",
    "labels=[]\n",
    "for i in range(7):\n",
    "\n",
    "    line = f.readline()\n",
    "    #print(line)\n",
    "    if \"emotion\" in line:\n",
    "        print(\"THE FIRST LINE IS SKIPPED\")\n",
    "        continue    \n",
    "\n",
    "    line = line.strip().split(\",\")\n",
    "    #print(line[1])\n",
    "    #print(line[2])\n",
    "    #print(line[3])\n",
    "    label = int(line[1])\n",
    "    imagelist = line[2].strip().split(\" \")\n",
    "    #print(imagelist[:10])\n",
    "\n",
    "\n",
    "    image = np.array(imagelist, dtype='float32').reshape(48,48)\n",
    "    image = image/255.0\n",
    "    #print(image.shape)\n",
    "    image_resized = resize(image, (pixelsize, pixelsize), anti_aliasing=True)\n",
    "    image_reshaped[:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
    "    #print(image_reshaped.shape)\n",
    "    label_onehot = np.zeros(7)\n",
    "    label_onehot[label]=1\n",
    "\n",
    "    #plt.imshow(image, cmap='gray')\n",
    "    #plt.show()\n",
    "\n",
    "    #plt.imshow(image_reshaped)\n",
    "    #plt.show()\n",
    "\n",
    "    images.append(image_reshaped)\n",
    "    labels.append(label_onehot)\n",
    "    \n",
    "npimages = np.array(images)\n",
    "print(npimages.shape)\n",
    "\n",
    "nplabels = np.array(labels)\n",
    "print(nplabels.shape)\n",
    "print(nplabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
    "    # dataset: Data path\n",
    "def get_CSVdata(inputPath, bs, mode=\"train\", aug=None, pixelsize = Resize_pixelsize):\n",
    "    # open the CSV file for reading\n",
    "    f = open(inputPath, \"r\")\n",
    "\n",
    "    # loop indefinitely\n",
    "    while True:\n",
    "        # initialize our batches of images and labels\n",
    "        images = []\n",
    "        labels = []\n",
    "        image_reshaped = np.zeros((pixelsize,pixelsize,3))\n",
    "\n",
    "        # keep looping until we reach our batch size\n",
    "        while len(images) < bs:\n",
    "            # attempt to read the next line of the CSV file\n",
    "            line = f.readline()\n",
    "            \n",
    "            if \"emotion\" in line:\n",
    "                continue            \n",
    "\n",
    "            # check to see if the line is empty, indicating we have\n",
    "            # reached the end of the file\n",
    "            if line == \"\":\n",
    "                # reset the file pointer to the beginning of the file\n",
    "                # and re-read the line\n",
    "                f.seek(0)\n",
    "                line = f.readline()\n",
    "                if \"emotion\" in line:\n",
    "                    continue \n",
    "\n",
    "                # if we are evaluating we should now break from our\n",
    "                # loop to ensure we don't continue to fill up the\n",
    "                # batch from samples at the beginning of the file\n",
    "                if mode == \"eval\":\n",
    "                    break\n",
    "\n",
    "            # extract the label and construct the image\n",
    "            line = line.strip().split(\",\")\n",
    "            label = int(line[1])\n",
    "            imagelist = line[2].strip().split(\" \")\n",
    "            image = np.array(imagelist, dtype='float32').reshape(48,48)\n",
    "            image = image/255.0\n",
    "            image_resized = resize(image, (pixelsize, pixelsize), anti_aliasing=True)\n",
    "            image_reshaped[:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
    "            label_onehot = np.zeros(7)\n",
    "            label_onehot[label]=1\n",
    "            # update our corresponding batches lists\n",
    "            images.append(image_reshaped)\n",
    "            labels.append(label_onehot)\n",
    "\n",
    "        # one-hot encode the labels\n",
    "        #labels = lb.transform(np.array(labels))\n",
    "\n",
    "        # if the data augmentation object is not None, apply it\n",
    "        if aug is not None:\n",
    "            (images, labels) = next(aug.flow(np.array(images),\n",
    "                np.array(labels), batch_size=bs))\n",
    "\n",
    "        # yield the batch to the calling function\n",
    "        yield (np.array(images), np.array(labels))    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BS = 64\n",
    "TRAIN_CSV = 'fer2013/train.csv'\n",
    "DEV_CSV = 'fer2013/dev.csv'\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range  = 10,\n",
    "    shear_range     = 10, # 10 degrees\n",
    "    zoom_range      = 0.1,\n",
    "    fill_mode       = 'reflect',\n",
    "    horizontal_flip = True)\n",
    "\n",
    "# initialize both the training and testing image generators\n",
    "train_generator = get_CSVdata(TRAIN_CSV, BS, mode=\"train\", aug=aug)\n",
    "dev_generator   = get_CSVdata(DEV_CSV, BS, mode=\"train\", aug=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#print (\"X_train shape: \" + str(X_train.shape))\n",
    "#print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "#print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "#print (\"Y_dev shape: \" + str(Y_dev.shape))\n",
    "\n",
    "print (\"X_train_res shape: \" + str(X_train_res.shape))\n",
    "print(\"Y_train_res shape: \" + str(Y_train_res.shape))\n",
    "print (\"X_dev_res shape: \" + str(X_dev_res.shape))\n",
    "print(\"Y_dev_res shape: \" + str(Y_dev_res.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3DpD608HuiQ"
   },
   "source": [
    "i = 10\n",
    "#image = X_train[i,:,:,:].reshape(48, 48)\n",
    "#plt.imshow(image, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "image_resized = X_train_res[i,:,:,:].reshape(Resize_pixelsize, Resize_pixelsize, 3)\n",
    "plt.imshow(image_resized)\n",
    "plt.show()\n",
    "print(Y_train_res[i])\n",
    "\n",
    "dev_resized = X_dev_res[i,:,:,:].reshape(Resize_pixelsize, Resize_pixelsize, 3)\n",
    "plt.imshow(dev_resized)\n",
    "plt.show()\n",
    "print(Y_dev_res[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi3lopGhZIuT"
   },
   "source": [
    "#Baseline model\n",
    "model = tf.keras.models.Sequential([\n",
    "    InputLayer(input_shape=(48,48,1),name=\"input\"),\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv1\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',padding='same',name=\"conv2\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(2,2),name=\"maxpool1\"),\n",
    "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv3\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Conv2D(filters=64,kernel_size=3,activation='relu',padding='same',name=\"conv4\"),\n",
    "    Dropout(0.25), BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(1024,input_shape=(24*24*64,1),activation='relu',name='fc1'),\n",
    "    Dense(7,input_shape=(1024,1),activation='softmax',name='fc-softmax')\n",
    "])\n",
    "\n",
    "print(\"Accuracy after training\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKzZuMBafv0a",
    "scrolled": true
   },
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, epochs=1, validation_data=(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_x = X_train_res[0:5000]\n",
    "small_y = Y_train_res[0:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLISdlaStbUn"
   },
   "source": [
    "history = custom_resnet.fit(\n",
    "    X_train_res,\n",
    "    Y_train_res,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_dev_res, Y_dev_res)\n",
    ")\n",
    "\n",
    "print('\\nhistory dict:', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training w/ generator...\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/20\n",
      "448/448 [==============================] - 519s 1s/step - loss: 1.8503 - acc: 0.2467 - val_loss: 1.8603 - val_acc: 0.2494\n",
      "Epoch 2/20\n",
      "214/448 [=============>................] - ETA: 4:10 - loss: 1.8140 - acc: 0.2484"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training w/ generator...\")\n",
    "H = custom_resnet.fit_generator(\n",
    "    generator = train_generator,\n",
    "    steps_per_epoch=28709 // BS,\n",
    "    validation_data=dev_generator,\n",
    "    validation_steps=3589 // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_resnet.save('transfer_learning_DG.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_resnet.fit_generator(\n",
    "    generator           = train_generator,\n",
    "    validation_data=(X_dev_res, Y_dev_res), \n",
    "    steps_per_epoch=len(X_train_res) // BS,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_resnet.evaluate(X_train_res, Y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_resnet.evaluate(X_dev_res, Y_dev_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "fer2013.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
