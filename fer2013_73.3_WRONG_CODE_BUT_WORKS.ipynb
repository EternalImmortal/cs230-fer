{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow_p36)",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/transfer-learning/fer2013_73.3_WRONG_CODE_BUT_WORKS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "outputId": "7c2fb727-bdc2-4302-c16d-d709ee68d792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras-vggface\n",
        "!pip install scikit-image\n",
        "!pip install pydot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-vggface in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.17.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (6.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (6.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.1.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from PyWavelets>=0.4.0->scikit-image) (1.17.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (45.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "outputId": "930b9643-1d42-46df-af20-62024bf8db4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.python.lib.io import file_io\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import *\n",
        "from keras.engine import Model\n",
        "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
        "import skimage\n",
        "from skimage.transform import rescale, resize\n",
        "\n",
        "import pydot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZczU8lGkX-",
        "colab_type": "code",
        "outputId": "5efbb1a6-84b9-4393-840c-13c43794e252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUcd6yIGduUW",
        "outputId": "c2524f3c-7379-43b4-aa28-8d8ac9480157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60q28mDHnN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "BS = 128\n",
        "DROPOUT_RATE = 0.5\n",
        "FROZEN_LAYER_NUM = 170\n",
        "\n",
        "ADAM_LEARNING_RATE = 0.001\n",
        "SGD_LEARNING_RATE = 0.01\n",
        "SGD_DECAY = 0.0001\n",
        "\n",
        "Resize_pixelsize = 197"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itKZtFV0F7b1",
        "colab_type": "code",
        "outputId": "17eb3f50-2123-41f8-aab1-d9fa4ba43fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg_notop = VGGFace(model='resnet50', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n",
        "last_layer = vgg_notop.get_layer('avg_pool').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(4096, activation='relu', name='fc6')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(1024, activation='relu', name='fc7')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "# l=0\n",
        "# for layer in vgg_notop.layers:\n",
        "#     print(layer,\"[\"+str(l)+\"]\")\n",
        "#     l=l+1\n",
        "    \n",
        "batch_norm_indices = [2, 6, 9, 13, 14, 18, 21, 24, 28, 31, 34, 38, 41, 45, 46, 53, 56, 60, 63, 66, 70, 73, 76, 80, 83, 87, 88, 92, 95, 98, 102, 105, 108, 112, 115, 118, 122, 125, 128, 132, 135, 138, 142, 145, 149, 150, 154, 157, 160, 164, 167, 170]\n",
        "for i in range(FROZEN_LAYER_NUM):\n",
        "    if i not in batch_norm_indices:\n",
        "        vgg_notop.layers[i].trainable = False\n",
        "# print('vgg layer 2 is trainable: ' + str(vgg_notop.layers[2].trainable))\n",
        "# print('vgg layer 3 is trainable: ' + str(vgg_notop.layers[3].trainable))\n",
        "\n",
        "out = Dense(7, activation='softmax', name='classifier')(x)\n",
        "\n",
        "model = Model(vgg_notop.input, out)\n",
        "\n",
        "\n",
        "optim = keras.optimizers.Adam(lr=ADAM_LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "sgd = keras.optimizers.SGD(lr=SGD_LEARNING_RATE, momentum=0.9, decay=SGD_DECAY, nesterov=True)\n",
        "rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_acc',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
        "\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# plot_model(model, to_file='model2.png', show_shapes=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7efb74dceb38> [0]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74dceef0> [1]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74dceda0> [2]\n",
            "<keras.layers.core.Activation object at 0x7efb74dced30> [3]\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7efb74dc9d68> [4]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74d58588> [5]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74d79b38> [6]\n",
            "<keras.layers.core.Activation object at 0x7efb74d79f28> [7]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74d7f940> [8]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74d345c0> [9]\n",
            "<keras.layers.core.Activation object at 0x7efb74d34550> [10]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74d40eb8> [11]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74cfffd0> [12]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74cf8dd8> [13]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74cc1668> [14]\n",
            "<keras.layers.merge.Add object at 0x7efb74cc1d68> [15]\n",
            "<keras.layers.core.Activation object at 0x7efb74c569e8> [16]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74c56fd0> [17]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74c88898> [18]\n",
            "<keras.layers.core.Activation object at 0x7efb74c88eb8> [19]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74c11be0> [20]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74c4a898> [21]\n",
            "<keras.layers.core.Activation object at 0x7efb74c4a828> [22]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74bd2da0> [23]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74c10198> [24]\n",
            "<keras.layers.merge.Add object at 0x7efb74c10780> [25]\n",
            "<keras.layers.core.Activation object at 0x7efb74ba56d8> [26]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74ba5f98> [27]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74b52f98> [28]\n",
            "<keras.layers.core.Activation object at 0x7efb74b5af98> [29]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74b5afd0> [30]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74b19550> [31]\n",
            "<keras.layers.core.Activation object at 0x7efb74b194e0> [32]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74b24f98> [33]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74ad8d68> [34]\n",
            "<keras.layers.merge.Add object at 0x7efb74ae2f60> [35]\n",
            "<keras.layers.core.Activation object at 0x7efb74af6c88> [36]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74afeda0> [37]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74aa1da0> [38]\n",
            "<keras.layers.core.Activation object at 0x7efb74aacdd8> [39]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74aace10> [40]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74a6c208> [41]\n",
            "<keras.layers.core.Activation object at 0x7efb74a6c828> [42]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74a76e10> [43]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74a2cf98> [44]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74a2ca20> [45]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb749f22b0> [46]\n",
            "<keras.layers.merge.Add object at 0x7efb749f2a90> [47]\n",
            "<keras.layers.core.Activation object at 0x7efb74a0df98> [48]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74993eb8> [49]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb749b1dd8> [50]\n",
            "<keras.layers.core.Activation object at 0x7efb749bfe10> [51]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb749bfc18> [52]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7497b4e0> [53]\n",
            "<keras.layers.core.Activation object at 0x7efb7497b470> [54]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74988f28> [55]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7493ecf8> [56]\n",
            "<keras.layers.merge.Add object at 0x7efb74946fd0> [57]\n",
            "<keras.layers.core.Activation object at 0x7efb748dcfd0> [58]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb748f8780> [59]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74907cf8> [60]\n",
            "<keras.layers.core.Activation object at 0x7efb74910d68> [61]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74910fd0> [62]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74851198> [63]\n",
            "<keras.layers.core.Activation object at 0x7efb748517b8> [64]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74858da0> [65]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74811a58> [66]\n",
            "<keras.layers.merge.Add object at 0x7efb748119e8> [67]\n",
            "<keras.layers.core.Activation object at 0x7efb74827f98> [68]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb7484d438> [69]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb747d9e48> [70]\n",
            "<keras.layers.core.Activation object at 0x7efb747e3c88> [71]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb747e3e10> [72]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7479ad68> [73]\n",
            "<keras.layers.core.Activation object at 0x7efb747a0f60> [74]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb747a9a58> [75]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74763710> [76]\n",
            "<keras.layers.merge.Add object at 0x7efb747636a0> [77]\n",
            "<keras.layers.core.Activation object at 0x7efb7477dfd0> [78]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb7471a0f0> [79]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74728b00> [80]\n",
            "<keras.layers.core.Activation object at 0x7efb74728e10> [81]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74733e10> [82]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb746e9a20> [83]\n",
            "<keras.layers.core.Activation object at 0x7efb746e9f98> [84]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb746f3f98> [85]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb746b49e8> [86]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb746b43c8> [87]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7467b2b0> [88]\n",
            "<keras.layers.merge.Add object at 0x7efb7467ba90> [89]\n",
            "<keras.layers.core.Activation object at 0x7efb74611f98> [90]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74619eb8> [91]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74643be0> [92]\n",
            "<keras.layers.core.Activation object at 0x7efb74643f60> [93]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb7464bd68> [94]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74603b00> [95]\n",
            "<keras.layers.core.Activation object at 0x7efb7460bdd8> [96]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb7460bbe0> [97]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb745cc4e0> [98]\n",
            "<keras.layers.merge.Add object at 0x7efb745cc470> [99]\n",
            "<keras.layers.core.Activation object at 0x7efb74561a20> [100]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74570d30> [101]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74590f98> [102]\n",
            "<keras.layers.core.Activation object at 0x7efb7451be10> [103]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb7451bf98> [104]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb744d3ef0> [105]\n",
            "<keras.layers.core.Activation object at 0x7efb744db5f8> [106]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb744e6be0> [107]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7449b908> [108]\n",
            "<keras.layers.merge.Add object at 0x7efb7449b898> [109]\n",
            "<keras.layers.core.Activation object at 0x7efb744b3ac8> [110]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb744c08d0> [111]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74464e10> [112]\n",
            "<keras.layers.core.Activation object at 0x7efb7446be10> [113]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb7446bc18> [114]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7442c5c0> [115]\n",
            "<keras.layers.core.Activation object at 0x7efb7442c550> [116]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74434eb8> [117]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb743edeb8> [118]\n",
            "<keras.layers.merge.Add object at 0x7efb743f3fd0> [119]\n",
            "<keras.layers.core.Activation object at 0x7efb74409e10> [120]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74410f98> [121]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb743b9b70> [122]\n",
            "<keras.layers.core.Activation object at 0x7efb743b9e80> [123]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb743c3e80> [124]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7437bb70> [125]\n",
            "<keras.layers.core.Activation object at 0x7efb74380e48> [126]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74380f60> [127]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb743415f8> [128]\n",
            "<keras.layers.merge.Add object at 0x7efb74341588> [129]\n",
            "<keras.layers.core.Activation object at 0x7efb742d7b38> [130]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb742d7cf8> [131]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb91791d68> [132]\n",
            "<keras.layers.core.Activation object at 0x7efb7450ce48> [133]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb742f3da0> [134]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb742b42b0> [135]\n",
            "<keras.layers.core.Activation object at 0x7efb742b48d0> [136]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb742baeb8> [137]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74271ba8> [138]\n",
            "<keras.layers.merge.Add object at 0x7efb74279f98> [139]\n",
            "<keras.layers.core.Activation object at 0x7efb7428dfd0> [140]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb742fcbe0> [141]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74242860> [142]\n",
            "<keras.layers.core.Activation object at 0x7efb74242fd0> [143]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74248b70> [144]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74200908> [145]\n",
            "<keras.layers.core.Activation object at 0x7efb74200898> [146]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74209e10> [147]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb741c9908> [148]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb741c92e8> [149]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb741902b0> [150]\n",
            "<keras.layers.merge.Add object at 0x7efb74190a90> [151]\n",
            "<keras.layers.core.Activation object at 0x7efb74128630> [152]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74135cc0> [153]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb740d9cc0> [154]\n",
            "<keras.layers.core.Activation object at 0x7efb740e0e48> [155]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb740e0fd0> [156]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74099cf8> [157]\n",
            "<keras.layers.core.Activation object at 0x7efb740a0fd0> [158]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb740a79e8> [159]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb7405f780> [160]\n",
            "<keras.layers.merge.Add object at 0x7efb7405f710> [161]\n",
            "<keras.layers.core.Activation object at 0x7efb74076940> [162]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb740185c0> [163]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb74027e48> [164]\n",
            "<keras.layers.core.Activation object at 0x7efb74031f28> [165]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb74031f60> [166]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb73fef438> [167]\n",
            "<keras.layers.core.Activation object at 0x7efb73fefa58> [168]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7efb73ffbf98> [169]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7efb73fb1d30> [170]\n",
            "<keras.layers.merge.Add object at 0x7efb73fb8f28> [171]\n",
            "<keras.layers.core.Activation object at 0x7efb73fccc88> [172]\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7efb73f55da0> [173]\n",
            "<keras.layers.pooling.GlobalAveragePooling2D object at 0x7efb73f78cc0> [174]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "colab": {}
      },
      "source": [
        "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
        "def get_data(datas, bs=32, aug=None, pixelsize=Resize_pixelsize):\n",
        "    # Data preparation\n",
        "    while True:\n",
        "      file_stream = file_io.FileIO(training_dataset_dir, mode='r')\n",
        "      datas = pd.read_csv(file_stream,iterator=True, chunksize=bs )\n",
        "      for data in datas:\n",
        "          data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "          X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "          X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "          X = X/255.0\n",
        "          X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "          for ind in range(X.shape[0]): \n",
        "              sample = X[ind]\n",
        "              sample = sample.reshape(48, 48)\n",
        "              image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "              X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "          Y_res = np.zeros((Y.size, Y.max()+1))\n",
        "          Y_res[np.arange(Y.size),Y] = 1\n",
        "          if aug is not None:\n",
        "              (X_res, Y_res) = next(aug.flow(np.array(X_res),\n",
        "                  Y_res, batch_size=bs))\n",
        "          yield  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQkWIk2kF0aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/train.csv'\n",
        "dev_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/dev.csv'\n",
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "train_generator = get_data(training_dataset_dir,  bs=BS, aug=None)\n",
        "dev_generator   = get_data(dev_dataset_dir, bs=BS, aug=None)\n",
        "test_generator   = get_data(test_dataset_dir, bs=BS, aug=None)\n",
        "    #X_dev_res, Y_dev_res  = get_data(dev_dataset_dir)\n",
        "\n",
        "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
        "# rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
        "# rotation_range:   Int. Degree range for random rotations\n",
        "# shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
        "# zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
        "# fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
        "# horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
        "\n",
        "\n",
        "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "#train_generator = train_datagen.flow(X_train_res, Y_train_res,  batch_size  = BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pLISdlaStbUn",
        "outputId": "caaa52db-4773-46b6-872b-4235f7e01580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator = train_generator,\n",
        "    validation_data=dev_generator, \n",
        "    steps_per_epoch=28709// BS,\n",
        "    validation_steps=3509 // BS,\n",
        "    shuffle=True,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[rlrop],\n",
        "    use_multiprocessing=True,\n",
        ") "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "224/224 [==============================] - 182s 810ms/step - loss: 2.1205 - acc: 0.3496 - val_loss: 1.2821 - val_acc: 0.5231\n",
            "Epoch 2/100\n",
            "224/224 [==============================] - 169s 755ms/step - loss: 1.3459 - acc: 0.4889 - val_loss: 1.0936 - val_acc: 0.5917\n",
            "Epoch 3/100\n",
            "224/224 [==============================] - 172s 770ms/step - loss: 1.2371 - acc: 0.5320 - val_loss: 1.0323 - val_acc: 0.6192\n",
            "Epoch 4/100\n",
            "224/224 [==============================] - 171s 764ms/step - loss: 1.1712 - acc: 0.5610 - val_loss: 0.9934 - val_acc: 0.6328\n",
            "Epoch 5/100\n",
            "224/224 [==============================] - 171s 762ms/step - loss: 1.1235 - acc: 0.5792 - val_loss: 0.9640 - val_acc: 0.6377\n",
            "Epoch 6/100\n",
            "224/224 [==============================] - 170s 760ms/step - loss: 1.0842 - acc: 0.5880 - val_loss: 0.8859 - val_acc: 0.6794\n",
            "Epoch 7/100\n",
            "224/224 [==============================] - 168s 752ms/step - loss: 1.0468 - acc: 0.6060 - val_loss: 0.8510 - val_acc: 0.7017\n",
            "Epoch 8/100\n",
            "224/224 [==============================] - 169s 753ms/step - loss: 1.0188 - acc: 0.6168 - val_loss: 0.8268 - val_acc: 0.7104\n",
            "Epoch 9/100\n",
            "224/224 [==============================] - 165s 738ms/step - loss: 0.9939 - acc: 0.6229 - val_loss: 0.8725 - val_acc: 0.6865\n",
            "Epoch 10/100\n",
            "224/224 [==============================] - 166s 741ms/step - loss: 0.9753 - acc: 0.6307 - val_loss: 0.8438 - val_acc: 0.6939\n",
            "Epoch 11/100\n",
            "224/224 [==============================] - 165s 736ms/step - loss: 0.9522 - acc: 0.6444 - val_loss: 0.7942 - val_acc: 0.7159\n",
            "Epoch 12/100\n",
            "224/224 [==============================] - 165s 737ms/step - loss: 0.9318 - acc: 0.6483 - val_loss: 0.7883 - val_acc: 0.7092\n",
            "Epoch 13/100\n",
            "224/224 [==============================] - 166s 740ms/step - loss: 0.9143 - acc: 0.6511 - val_loss: 0.7864 - val_acc: 0.7150\n",
            "Epoch 14/100\n",
            "224/224 [==============================] - 167s 745ms/step - loss: 0.8959 - acc: 0.6597 - val_loss: 0.7549 - val_acc: 0.7361\n",
            "Epoch 15/100\n",
            "224/224 [==============================] - 167s 744ms/step - loss: 0.8776 - acc: 0.6675 - val_loss: 0.6865 - val_acc: 0.7691\n",
            "Epoch 16/100\n",
            "224/224 [==============================] - 166s 740ms/step - loss: 0.8605 - acc: 0.6729 - val_loss: 0.6884 - val_acc: 0.7778\n",
            "Epoch 17/100\n",
            "224/224 [==============================] - 165s 736ms/step - loss: 0.8436 - acc: 0.6814 - val_loss: 0.7080 - val_acc: 0.7599\n",
            "Epoch 18/100\n",
            "224/224 [==============================] - 166s 739ms/step - loss: 0.8345 - acc: 0.6828 - val_loss: 0.6960 - val_acc: 0.7697\n",
            "Epoch 19/100\n",
            "224/224 [==============================] - 166s 739ms/step - loss: 0.8079 - acc: 0.6933 - val_loss: 0.6710 - val_acc: 0.7821\n",
            "Epoch 20/100\n",
            "224/224 [==============================] - 166s 739ms/step - loss: 0.8004 - acc: 0.6968 - val_loss: 0.6415 - val_acc: 0.7905\n",
            "Epoch 21/100\n",
            "224/224 [==============================] - 165s 737ms/step - loss: 0.7796 - acc: 0.7057 - val_loss: 0.6271 - val_acc: 0.7925\n",
            "Epoch 22/100\n",
            "224/224 [==============================] - 163s 730ms/step - loss: 0.7668 - acc: 0.7087 - val_loss: 0.6025 - val_acc: 0.8102\n",
            "Epoch 23/100\n",
            "224/224 [==============================] - 164s 731ms/step - loss: 0.7512 - acc: 0.7159 - val_loss: 0.5598 - val_acc: 0.8368\n",
            "Epoch 24/100\n",
            "224/224 [==============================] - 166s 739ms/step - loss: 0.7443 - acc: 0.7173 - val_loss: 0.5644 - val_acc: 0.8391\n",
            "Epoch 25/100\n",
            "224/224 [==============================] - 167s 744ms/step - loss: 0.7318 - acc: 0.7228 - val_loss: 0.5474 - val_acc: 0.8478\n",
            "Epoch 26/100\n",
            "224/224 [==============================] - 167s 745ms/step - loss: 0.7148 - acc: 0.7320 - val_loss: 0.5595 - val_acc: 0.8406\n",
            "Epoch 27/100\n",
            "224/224 [==============================] - 166s 741ms/step - loss: 0.6958 - acc: 0.7339 - val_loss: 0.5209 - val_acc: 0.8478\n",
            "Epoch 28/100\n",
            "224/224 [==============================] - 164s 732ms/step - loss: 0.6850 - acc: 0.7388 - val_loss: 0.5034 - val_acc: 0.8649\n",
            "Epoch 29/100\n",
            "224/224 [==============================] - 165s 735ms/step - loss: 0.6795 - acc: 0.7438 - val_loss: 0.5099 - val_acc: 0.8594\n",
            "Epoch 30/100\n",
            "224/224 [==============================] - 165s 738ms/step - loss: 0.6618 - acc: 0.7510 - val_loss: 0.4795 - val_acc: 0.8736\n",
            "Epoch 31/100\n",
            "224/224 [==============================] - 165s 739ms/step - loss: 0.6499 - acc: 0.7561 - val_loss: 0.4355 - val_acc: 0.8863\n",
            "Epoch 32/100\n",
            "224/224 [==============================] - 164s 732ms/step - loss: 0.6392 - acc: 0.7593 - val_loss: 0.4254 - val_acc: 0.8976\n",
            "Epoch 33/100\n",
            "224/224 [==============================] - 164s 733ms/step - loss: 0.6273 - acc: 0.7600 - val_loss: 0.4350 - val_acc: 0.8900\n",
            "Epoch 34/100\n",
            "224/224 [==============================] - 166s 742ms/step - loss: 0.6134 - acc: 0.7706 - val_loss: 0.4324 - val_acc: 0.8954\n",
            "Epoch 35/100\n",
            "224/224 [==============================] - 169s 753ms/step - loss: 0.6044 - acc: 0.7707 - val_loss: 0.4220 - val_acc: 0.8970\n",
            "Epoch 36/100\n",
            "224/224 [==============================] - 169s 754ms/step - loss: 0.5911 - acc: 0.7769 - val_loss: 0.3858 - val_acc: 0.9042\n",
            "Epoch 37/100\n",
            "224/224 [==============================] - 169s 755ms/step - loss: 0.5814 - acc: 0.7791 - val_loss: 0.3821 - val_acc: 0.9112\n",
            "Epoch 38/100\n",
            "224/224 [==============================] - 168s 750ms/step - loss: 0.5696 - acc: 0.7865 - val_loss: 0.3739 - val_acc: 0.9129\n",
            "Epoch 39/100\n",
            "224/224 [==============================] - 168s 749ms/step - loss: 0.5580 - acc: 0.7857 - val_loss: 0.3475 - val_acc: 0.9256\n",
            "Epoch 40/100\n",
            "224/224 [==============================] - 166s 740ms/step - loss: 0.5436 - acc: 0.7956 - val_loss: 0.3201 - val_acc: 0.9395\n",
            "Epoch 41/100\n",
            "224/224 [==============================] - 167s 744ms/step - loss: 0.5378 - acc: 0.7978 - val_loss: 0.3298 - val_acc: 0.9271\n",
            "Epoch 42/100\n",
            "224/224 [==============================] - 167s 745ms/step - loss: 0.5339 - acc: 0.8009 - val_loss: 0.3224 - val_acc: 0.9340\n",
            "Epoch 43/100\n",
            "224/224 [==============================] - 168s 748ms/step - loss: 0.5286 - acc: 0.7994 - val_loss: 0.3228 - val_acc: 0.9355\n",
            "Epoch 44/100\n",
            "224/224 [==============================] - 166s 741ms/step - loss: 0.5054 - acc: 0.8091 - val_loss: 0.2987 - val_acc: 0.9413\n",
            "Epoch 45/100\n",
            "224/224 [==============================] - 172s 769ms/step - loss: 0.5033 - acc: 0.8104 - val_loss: 0.2887 - val_acc: 0.9482\n",
            "Epoch 46/100\n",
            "224/224 [==============================] - 171s 765ms/step - loss: 0.4948 - acc: 0.8122 - val_loss: 0.2792 - val_acc: 0.9476\n",
            "Epoch 47/100\n",
            "224/224 [==============================] - 172s 770ms/step - loss: 0.4820 - acc: 0.8196 - val_loss: 0.2531 - val_acc: 0.9552\n",
            "Epoch 48/100\n",
            "224/224 [==============================] - 174s 778ms/step - loss: 0.4806 - acc: 0.8198 - val_loss: 0.2408 - val_acc: 0.9690\n",
            "Epoch 49/100\n",
            "224/224 [==============================] - 173s 773ms/step - loss: 0.4683 - acc: 0.8273 - val_loss: 0.2585 - val_acc: 0.9525\n",
            "Epoch 50/100\n",
            "224/224 [==============================] - 173s 770ms/step - loss: 0.4543 - acc: 0.8283 - val_loss: 0.2295 - val_acc: 0.9643\n",
            "Epoch 51/100\n",
            "224/224 [==============================] - 170s 757ms/step - loss: 0.4362 - acc: 0.8359 - val_loss: 0.2317 - val_acc: 0.9664\n",
            "Epoch 52/100\n",
            "224/224 [==============================] - 170s 758ms/step - loss: 0.4373 - acc: 0.8344 - val_loss: 0.2177 - val_acc: 0.9618\n",
            "Epoch 53/100\n",
            "224/224 [==============================] - 170s 760ms/step - loss: 0.4395 - acc: 0.8354 - val_loss: 0.2105 - val_acc: 0.9685\n",
            "Epoch 54/100\n",
            "224/224 [==============================] - 166s 742ms/step - loss: 0.4245 - acc: 0.8410 - val_loss: 0.2054 - val_acc: 0.9716\n",
            "Epoch 55/100\n",
            "224/224 [==============================] - 166s 742ms/step - loss: 0.4142 - acc: 0.8469 - val_loss: 0.1948 - val_acc: 0.9760\n",
            "Epoch 56/100\n",
            "224/224 [==============================] - 174s 776ms/step - loss: 0.4099 - acc: 0.8485 - val_loss: 0.1699 - val_acc: 0.9774\n",
            "Epoch 57/100\n",
            "224/224 [==============================] - 171s 765ms/step - loss: 0.4009 - acc: 0.8493 - val_loss: 0.1842 - val_acc: 0.9786\n",
            "Epoch 58/100\n",
            "224/224 [==============================] - 169s 757ms/step - loss: 0.3920 - acc: 0.8526 - val_loss: 0.1744 - val_acc: 0.9751\n",
            "Epoch 59/100\n",
            "224/224 [==============================] - 168s 748ms/step - loss: 0.3850 - acc: 0.8579 - val_loss: 0.1753 - val_acc: 0.9777\n",
            "Epoch 60/100\n",
            "224/224 [==============================] - 167s 744ms/step - loss: 0.3806 - acc: 0.8580 - val_loss: 0.1705 - val_acc: 0.9719\n",
            "Epoch 61/100\n",
            "224/224 [==============================] - 165s 738ms/step - loss: 0.3800 - acc: 0.8586 - val_loss: 0.1631 - val_acc: 0.9789\n",
            "Epoch 62/100\n",
            "224/224 [==============================] - 169s 753ms/step - loss: 0.3749 - acc: 0.8606 - val_loss: 0.1565 - val_acc: 0.9818\n",
            "Epoch 63/100\n",
            "224/224 [==============================] - 172s 769ms/step - loss: 0.3588 - acc: 0.8663 - val_loss: 0.1487 - val_acc: 0.9823\n",
            "Epoch 64/100\n",
            "224/224 [==============================] - 171s 762ms/step - loss: 0.3562 - acc: 0.8705 - val_loss: 0.1329 - val_acc: 0.9878\n",
            "Epoch 65/100\n",
            "224/224 [==============================] - 172s 767ms/step - loss: 0.3477 - acc: 0.8705 - val_loss: 0.1348 - val_acc: 0.9838\n",
            "Epoch 66/100\n",
            "224/224 [==============================] - 172s 767ms/step - loss: 0.3399 - acc: 0.8733 - val_loss: 0.1363 - val_acc: 0.9821\n",
            "Epoch 67/100\n",
            "224/224 [==============================] - 172s 769ms/step - loss: 0.3375 - acc: 0.8752 - val_loss: 0.1331 - val_acc: 0.9813\n",
            "Epoch 68/100\n",
            "224/224 [==============================] - 174s 777ms/step - loss: 0.3274 - acc: 0.8784 - val_loss: 0.1288 - val_acc: 0.9829\n",
            "Epoch 69/100\n",
            "224/224 [==============================] - 174s 779ms/step - loss: 0.3342 - acc: 0.8754 - val_loss: 0.1258 - val_acc: 0.9803\n",
            "Epoch 70/100\n",
            "224/224 [==============================] - 172s 767ms/step - loss: 0.3170 - acc: 0.8831 - val_loss: 0.1156 - val_acc: 0.9861\n",
            "Epoch 71/100\n",
            "224/224 [==============================] - 171s 764ms/step - loss: 0.3170 - acc: 0.8818 - val_loss: 0.1122 - val_acc: 0.9850\n",
            "Epoch 72/100\n",
            "224/224 [==============================] - 171s 764ms/step - loss: 0.3183 - acc: 0.8818 - val_loss: 0.1035 - val_acc: 0.9902\n",
            "Epoch 73/100\n",
            "224/224 [==============================] - 170s 760ms/step - loss: 0.3047 - acc: 0.8880 - val_loss: 0.0999 - val_acc: 0.9905\n",
            "Epoch 74/100\n",
            "224/224 [==============================] - 167s 748ms/step - loss: 0.3060 - acc: 0.8874 - val_loss: 0.1059 - val_acc: 0.9861\n",
            "Epoch 75/100\n",
            "224/224 [==============================] - 168s 751ms/step - loss: 0.2970 - acc: 0.8903 - val_loss: 0.0964 - val_acc: 0.9863\n",
            "Epoch 76/100\n",
            "224/224 [==============================] - 166s 742ms/step - loss: 0.3003 - acc: 0.8907 - val_loss: 0.1008 - val_acc: 0.9884\n",
            "Epoch 77/100\n",
            "224/224 [==============================] - 168s 752ms/step - loss: 0.2904 - acc: 0.8948 - val_loss: 0.0972 - val_acc: 0.9829\n",
            "Epoch 78/100\n",
            "224/224 [==============================] - 170s 758ms/step - loss: 0.2810 - acc: 0.8958 - val_loss: 0.0911 - val_acc: 0.9867\n",
            "Epoch 79/100\n",
            "224/224 [==============================] - 170s 759ms/step - loss: 0.2848 - acc: 0.8934 - val_loss: 0.0842 - val_acc: 0.9919\n",
            "Epoch 80/100\n",
            "224/224 [==============================] - 168s 752ms/step - loss: 0.2714 - acc: 0.9025 - val_loss: 0.0784 - val_acc: 0.9893\n",
            "Epoch 81/100\n",
            "224/224 [==============================] - 168s 748ms/step - loss: 0.2844 - acc: 0.8954 - val_loss: 0.0789 - val_acc: 0.9899\n",
            "Epoch 82/100\n",
            "224/224 [==============================] - 168s 749ms/step - loss: 0.2728 - acc: 0.8995 - val_loss: 0.0779 - val_acc: 0.9916\n",
            "Epoch 83/100\n",
            "224/224 [==============================] - 167s 745ms/step - loss: 0.2672 - acc: 0.9022 - val_loss: 0.0820 - val_acc: 0.9890\n",
            "Epoch 84/100\n",
            "224/224 [==============================] - 168s 750ms/step - loss: 0.2590 - acc: 0.9046 - val_loss: 0.0809 - val_acc: 0.9884\n",
            "Epoch 85/100\n",
            "224/224 [==============================] - 167s 747ms/step - loss: 0.2670 - acc: 0.9022 - val_loss: 0.0769 - val_acc: 0.9870\n",
            "Epoch 86/100\n",
            "224/224 [==============================] - 168s 748ms/step - loss: 0.2530 - acc: 0.9078 - val_loss: 0.0756 - val_acc: 0.9881\n",
            "Epoch 87/100\n",
            "224/224 [==============================] - 167s 745ms/step - loss: 0.2526 - acc: 0.9087 - val_loss: 0.0709 - val_acc: 0.9933\n",
            "Epoch 88/100\n",
            "224/224 [==============================] - 169s 755ms/step - loss: 0.2523 - acc: 0.9079 - val_loss: 0.0704 - val_acc: 0.9884\n",
            "Epoch 89/100\n",
            "224/224 [==============================] - 172s 769ms/step - loss: 0.2523 - acc: 0.9088 - val_loss: 0.0644 - val_acc: 0.9916\n",
            "Epoch 90/100\n",
            "224/224 [==============================] - 172s 770ms/step - loss: 0.2485 - acc: 0.9103 - val_loss: 0.0645 - val_acc: 0.9910\n",
            "Epoch 91/100\n",
            "224/224 [==============================] - 171s 762ms/step - loss: 0.2416 - acc: 0.9124 - val_loss: 0.0655 - val_acc: 0.9890\n",
            "Epoch 92/100\n",
            "224/224 [==============================] - 172s 770ms/step - loss: 0.2394 - acc: 0.9133 - val_loss: 0.0665 - val_acc: 0.9887\n",
            "Epoch 93/100\n",
            "224/224 [==============================] - 169s 755ms/step - loss: 0.2371 - acc: 0.9129 - val_loss: 0.0643 - val_acc: 0.9881\n",
            "Epoch 94/100\n",
            "224/224 [==============================] - 169s 754ms/step - loss: 0.2452 - acc: 0.9079 - val_loss: 0.0657 - val_acc: 0.9878\n",
            "Epoch 95/100\n",
            "224/224 [==============================] - 172s 769ms/step - loss: 0.2326 - acc: 0.9160 - val_loss: 0.0608 - val_acc: 0.9954\n",
            "Epoch 96/100\n",
            "224/224 [==============================] - 169s 753ms/step - loss: 0.2280 - acc: 0.9164 - val_loss: 0.0573 - val_acc: 0.9907\n",
            "Epoch 97/100\n",
            "224/224 [==============================] - 168s 750ms/step - loss: 0.2227 - acc: 0.9178 - val_loss: 0.0541 - val_acc: 0.9925\n",
            "Epoch 98/100\n",
            "224/224 [==============================] - 171s 763ms/step - loss: 0.2236 - acc: 0.9189 - val_loss: 0.0535 - val_acc: 0.9931\n",
            "Epoch 99/100\n",
            "224/224 [==============================] - 172s 770ms/step - loss: 0.2195 - acc: 0.9192 - val_loss: 0.0521 - val_acc: 0.9910\n",
            "Epoch 100/100\n",
            "224/224 [==============================] - 172s 769ms/step - loss: 0.2110 - acc: 0.9243 - val_loss: 0.0510 - val_acc: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSSv08SHF0bC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "48140fff-e78e-4b16-9f49-0c86d312d477"
      },
      "source": [
        "print('\\n# Evaluate on dev data')\n",
        "results_dev = model.evaluate_generator(dev_generator, 3509 // BS)\n",
        "print('dev loss, dev acc:', results_dev)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on dev data\n",
            "dev loss, dev acc: [0.05221803914065714, 0.9913194444444444]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4sDYDlOsqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d96c8fc0-3189-4cc4-c112-04fc82ec7b06"
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "results_test = model.evaluate_generator(test_generator, 3509 // BS)\n",
        "print('test loss, test acc:', results_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "test loss, test acc: [0.05221803914065714, 0.9913194444444444]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9f7smhHUQus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "ce65f60c-7e9a-49ed-dc30-08c2fca6ceeb"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ywRGGOMx1kiMMYYj7NEYIwxHvf/AcAb4E7gki42AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSimH+//yiAdjICTw1AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QKHTmJQhi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_str = '-SGD_LR_%.5f' % SGD_LEARNING_RATE\n",
        "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
        "bs_str = '-BS_' + str(BS)\n",
        "dropout_str = '-DROPOUT_' + str(DROPOUT_RATE)\n",
        "test_acc = 'test_acc_%.3f' % results_test[1]\n",
        "model.save('/content/drive/My Drive/cs230 project/models/tl/tl' + lr_str + epoch_str + bs_str + dropout_str + test_acc + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqHDa5Hwiih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_for_test(dataset, pixelsize = Resize_pixelsize):\n",
        "    file_stream = file_io.FileIO(dataset, mode='r')\n",
        "    data = pd.read_csv(file_stream)\n",
        "    data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "\n",
        "    X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "    X = X/255.0\n",
        "    X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "    for ind in range(X.shape[0]):  #X_dev.shape[0]\n",
        "        sample = X[ind]\n",
        "        sample = sample.reshape(48, 48)\n",
        "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "        X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "    Y_res = np.zeros((Y.size, Y.max()+1))\n",
        "    Y_res[np.arange(Y.size),Y] = 1\n",
        "    \n",
        "    return  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MAUWRXFxcm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "X_test_res, Y_test_res  = get_data_for_test(test_dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulH4ikEJxhm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fd743d4a-f12c-444d-a003-c260d24bf0d0"
      },
      "source": [
        "model.evaluate(X_test_res, Y_test_res)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589/3589 [==============================] - 8s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9163703456932072, 0.732237392047814]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cHBx0OcUYWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# configure image data augmentation\n",
        "tta_aug = ImageDataGenerator(\n",
        "    # rotation_range  = 10,\n",
        "    # shear_range     = 10, # 10 degrees\n",
        "    # zoom_range      = 0.1,\n",
        "    # fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "# make a prediction using test-time augmentation\n",
        "def tta_prediction(model, image, n_examples):\n",
        "\t# convert image into dataset\n",
        "\tsamples = np.expand_dims(image, 0)\n",
        "  test_generator = get_data(test_dataset_dir, bs=BS, aug=tta_aug)\n",
        "\tit = test_generator.flow(samples, batch_size=n_examples)\n",
        "\tyhats = model.predict_generator(it, steps=n_examples, verbose=0)\n",
        "\t# sum across predictions\n",
        "\tsummed = np.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\treturn np.argmax(summed)\n",
        " \n",
        " # evaluate a model on a dataset using test-time augmentation\n",
        "def tta_evaluate_model(model, testX, testY):\n",
        "\t# configure image data augmentation\n",
        "\tdatagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\t# define the number of augmented images to generate per test set image\n",
        "\tn_examples_per_image = 7\n",
        "\tyhats = list()\n",
        "\tfor i in range(len(testX)):\n",
        "\t\t# make augmented prediction\n",
        "\t\tyhat = tta_prediction(datagen, model, testX[i], n_examples_per_image)\n",
        "\t\t# store for evaluation\n",
        "\t\tyhats.append(yhat)\n",
        "\t# calculate accuracy\n",
        "\ttestY_labels = np.argmax(testY, axis=1)\n",
        "\tacc = accuracy_score(testY_labels, yhats)\n",
        "\treturn acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78X7l-0txbT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ia-TsrIUf9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "TTA_results_test = tta_evaluate_model(model, X_test, Y_test)\n",
        "print('test loss, test acc:', results_test)\n",
        "print('TTA test acc:', TTA_results_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}