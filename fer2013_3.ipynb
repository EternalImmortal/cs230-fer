{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fer2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow_p36)",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amilkh/cs230-fer/blob/transfer-learning/fer2013_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwdg7Sv3XBaP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "5d0abbe9-2dfb-48a1-d61b-2d3e60ea4624"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras-vggface\n",
        "!pip install scikit-image\n",
        "!pip install pydot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-vggface in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.4.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.17.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (6.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface) (1.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.1.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (6.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from PyWavelets>=0.4.0->scikit-image) (1.17.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (45.2.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nz38mJZXN_P",
        "outputId": "59e712e4-c2d8-4863-9d3f-70b57a253bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.python.lib.io import file_io\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import *\n",
        "from keras.engine import Model\n",
        "from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n",
        "import skimage\n",
        "from skimage.transform import rescale, resize\n",
        "\n",
        "import pydot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZczU8lGkX-",
        "colab_type": "code",
        "outputId": "9f2e16d2-5c20-429b-a120-1f6287770877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUcd6yIGduUW",
        "outputId": "060d2734-8b89-4964-f538-d8f03af597a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60q28mDHnN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "BS = 128\n",
        "DROPOUT_RATE = 0.5\n",
        "FROZEN_LAYER_NUM = 170\n",
        "\n",
        "ADAM_LEARNING_RATE = 0.001\n",
        "SGD_LEARNING_RATE = 0.01\n",
        "SGD_DECAY = 0.0001\n",
        "\n",
        "Resize_pixelsize = 197"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itKZtFV0F7b1",
        "colab_type": "code",
        "outputId": "c807eb65-0279-4313-e0fd-2a7414a470e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg_notop = VGGFace(model='resnet50', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n",
        "last_layer = vgg_notop.get_layer('avg_pool').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(4096, activation='relu', name='fc6')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(1024, activation='relu', name='fc7')(x)\n",
        "# x = Dropout(DROPOUT_RATE)(x)\n",
        "l=0\n",
        "for layer in vgg_notop.layers:\n",
        "    print(layer,\"[\"+str(l)+\"]\")\n",
        "    l=l+1\n",
        "    \n",
        "batch_norm_indices = [2, 6, 9, 13, 14, 18, 21, 24, 28, 31, 34, 38, 41, 45, 46, 53, 56, 60, 63, 66, 70, 73, 76, 80, 83, 87, 88, 92, 95, 98, 102, 105, 108, 112, 115, 118, 122, 125, 128, 132, 135, 138, 142, 145, 149, 150, 154, 157, 160, 164, 167, 170]\n",
        "for i in range(FROZEN_LAYER_NUM):\n",
        "    if i not in batch_norm_indices:\n",
        "        vgg_notop.layers[i].trainable = False\n",
        "# print('vgg layer 2 is trainable: ' + str(vgg_notop.layers[2].trainable))\n",
        "# print('vgg layer 3 is trainable: ' + str(vgg_notop.layers[3].trainable))\n",
        "\n",
        "out = Dense(7, activation='softmax', name='classifier')(x)\n",
        "\n",
        "model = Model(vgg_notop.input, out)\n",
        "\n",
        "\n",
        "optim = keras.optimizers.Adam(lr=ADAM_LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "sgd = keras.optimizers.SGD(lr=SGD_LEARNING_RATE, momentum=0.9, decay=SGD_DECAY, nesterov=True)\n",
        "rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_acc',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
        "\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# plot_model(model, to_file='model2.png', show_shapes=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "<keras.engine.input_layer.InputLayer object at 0x7fe896f1a908> [0]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe896f1a9e8> [1]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe896f1ad68> [2]\n",
            "<keras.layers.core.Activation object at 0x7fe896f1ae48> [3]\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fe896706940> [4]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8966fdf60> [5]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88665dcc0> [6]\n",
            "<keras.layers.core.Activation object at 0x7fe88665df60> [7]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8866679b0> [8]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88661fb38> [9]\n",
            "<keras.layers.core.Activation object at 0x7fe88661fcf8> [10]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88662d240> [11]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8865def98> [12]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8865dbd30> [13]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8865997f0> [14]\n",
            "<keras.layers.merge.Add object at 0x7fe886599d30> [15]\n",
            "<keras.layers.core.Activation object at 0x7fe8865b0d30> [16]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8865530f0> [17]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe886561438> [18]\n",
            "<keras.layers.core.Activation object at 0x7fe886561630> [19]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88656cd68> [20]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8865229e8> [21]\n",
            "<keras.layers.core.Activation object at 0x7fe886522b70> [22]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe886528be0> [23]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8864e9a20> [24]\n",
            "<keras.layers.merge.Add object at 0x7fe8864e9be0> [25]\n",
            "<keras.layers.core.Activation object at 0x7fe88647db00> [26]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88647dcc0> [27]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8864af3c8> [28]\n",
            "<keras.layers.core.Activation object at 0x7fe8864af588> [29]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe886439cc0> [30]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88646a940> [31]\n",
            "<keras.layers.core.Activation object at 0x7fe88646aac8> [32]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8863faef0> [33]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8863ba978> [34]\n",
            "<keras.layers.merge.Add object at 0x7fe8863bab38> [35]\n",
            "<keras.layers.core.Activation object at 0x7fe8863d1a58> [36]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8863c3f28> [37]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe886383320> [38]\n",
            "<keras.layers.core.Activation object at 0x7fe886383f98> [39]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88638bc18> [40]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe886344898> [41]\n",
            "<keras.layers.core.Activation object at 0x7fe886344a20> [42]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8863515f8> [43]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88630ba58> [44]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88630b8d0> [45]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8862cacf8> [46]\n",
            "<keras.layers.merge.Add object at 0x7fe8862cada0> [47]\n",
            "<keras.layers.core.Activation object at 0x7fe8862e7f98> [48]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8862835f8> [49]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe886291fd0> [50]\n",
            "<keras.layers.core.Activation object at 0x7fe886299c18> [51]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8862a22b0> [52]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe886252fd0> [53]\n",
            "<keras.layers.core.Activation object at 0x7fe88625b710> [54]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88626a550> [55]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88621b8d0> [56]\n",
            "<keras.layers.merge.Add object at 0x7fe88621ba58> [57]\n",
            "<keras.layers.core.Activation object at 0x7fe886235fd0> [58]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8861d5550> [59]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8861e18d0> [60]\n",
            "<keras.layers.core.Activation object at 0x7fe8861e1ac8> [61]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8861f4208> [62]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8861a5ef0> [63]\n",
            "<keras.layers.core.Activation object at 0x7fe8861ac668> [64]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8861b4ba8> [65]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88616efd0> [66]\n",
            "<keras.layers.merge.Add object at 0x7fe88616e978> [67]\n",
            "<keras.layers.core.Activation object at 0x7fe886104f60> [68]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8861284a8> [69]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe886133828> [70]\n",
            "<keras.layers.core.Activation object at 0x7fe8861339e8> [71]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8860c4160> [72]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8860f5da0> [73]\n",
            "<keras.layers.core.Activation object at 0x7fe88607dfd0> [74]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe886087b00> [75]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88603edd8> [76]\n",
            "<keras.layers.merge.Add object at 0x7fe88603e8d0> [77]\n",
            "<keras.layers.core.Activation object at 0x7fe886053b38> [78]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88604e4e0> [79]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe880232780> [80]\n",
            "<keras.layers.core.Activation object at 0x7fe880232940> [81]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88023ae10> [82]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8801f2e10> [83]\n",
            "<keras.layers.core.Activation object at 0x7fe8801faf60> [84]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe880200a58> [85]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8801b9828> [86]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8801b9d30> [87]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe880182898> [88]\n",
            "<keras.layers.merge.Add object at 0x7fe880182dd8> [89]\n",
            "<keras.layers.core.Activation object at 0x7fe8801a0f98> [90]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88013c518> [91]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe880149be0> [92]\n",
            "<keras.layers.core.Activation object at 0x7fe880154e80> [93]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88015a550> [94]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe880113828> [95]\n",
            "<keras.layers.core.Activation object at 0x7fe8801139b0> [96]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88011def0> [97]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8800c8b70> [98]\n",
            "<keras.layers.merge.Add object at 0x7fe8800d0f60> [99]\n",
            "<keras.layers.core.Activation object at 0x7fe8800e2fd0> [100]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe880067d30> [101]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe880091978> [102]\n",
            "<keras.layers.core.Activation object at 0x7fe880091f28> [103]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe880044e80> [104]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe88004ffd0> [105]\n",
            "<keras.layers.core.Activation object at 0x7fe88004f978> [106]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe88005f588> [107]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8219ad860> [108]\n",
            "<keras.layers.merge.Add object at 0x7fe8219ad9e8> [109]\n",
            "<keras.layers.core.Activation object at 0x7fe821946940> [110]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe821946f98> [111]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821979908> [112]\n",
            "<keras.layers.core.Activation object at 0x7fe821979b00> [113]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe82190a240> [114]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821939f28> [115]\n",
            "<keras.layers.core.Activation object at 0x7fe8218c16a0> [116]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8218cbc88> [117]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821881a20> [118]\n",
            "<keras.layers.merge.Add object at 0x7fe8218819b0> [119]\n",
            "<keras.layers.core.Activation object at 0x7fe821899f98> [120]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8218a4a20> [121]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8218520f0> [122]\n",
            "<keras.layers.core.Activation object at 0x7fe821852f28> [123]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe821858940> [124]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821811b70> [125]\n",
            "<keras.layers.core.Activation object at 0x7fe821811668> [126]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe82181fcc0> [127]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8217d1f98> [128]\n",
            "<keras.layers.merge.Add object at 0x7fe8217d86d8> [129]\n",
            "<keras.layers.core.Activation object at 0x7fe8217f0630> [130]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8217f0f98> [131]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8217a05f8> [132]\n",
            "<keras.layers.core.Activation object at 0x7fe8217a07b8> [133]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8217aaef0> [134]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821762b70> [135]\n",
            "<keras.layers.core.Activation object at 0x7fe821768f60> [136]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8217718d0> [137]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821729ba8> [138]\n",
            "<keras.layers.merge.Add object at 0x7fe8217296a0> [139]\n",
            "<keras.layers.core.Activation object at 0x7fe8216c1908> [140]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8216e4908> [141]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8216f0c50> [142]\n",
            "<keras.layers.core.Activation object at 0x7fe8216f9eb8> [143]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe821680588> [144]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8216b9860> [145]\n",
            "<keras.layers.core.Activation object at 0x7fe8216b99e8> [146]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe821643f28> [147]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe821600f98> [148]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821679ba8> [149]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8215c1d68> [150]\n",
            "<keras.layers.merge.Add object at 0x7fe8215c1e10> [151]\n",
            "<keras.layers.core.Activation object at 0x7fe8215e0f60> [152]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8215e8b70> [153]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8215930f0> [154]\n",
            "<keras.layers.core.Activation object at 0x7fe821593fd0> [155]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe82159bac8> [156]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821552898> [157]\n",
            "<keras.layers.core.Activation object at 0x7fe821552828> [158]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe821559fd0> [159]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8215196d8> [160]\n",
            "<keras.layers.merge.Add object at 0x7fe821519860> [161]\n",
            "<keras.layers.core.Activation object at 0x7fe82152e7b8> [162]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe82152efd0> [163]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8214e1780> [164]\n",
            "<keras.layers.core.Activation object at 0x7fe8214e1940> [165]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8214eaf60> [166]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe8214a2cf8> [167]\n",
            "<keras.layers.core.Activation object at 0x7fe8214aaf60> [168]\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fe8214b2a58> [169]\n",
            "<keras.layers.normalization.BatchNormalization object at 0x7fe821469d30> [170]\n",
            "<keras.layers.merge.Add object at 0x7fe821469828> [171]\n",
            "<keras.layers.core.Activation object at 0x7fe821401a90> [172]\n",
            "<keras.layers.pooling.AveragePooling2D object at 0x7fe82147b438> [173]\n",
            "<keras.layers.pooling.GlobalAveragePooling2D object at 0x7fe8214327b8> [174]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjKPXZ3TX3Jb",
        "colab": {}
      },
      "source": [
        "# Function that reads the data from the csv file, increases the size of the images and returns the images and their labels\n",
        "def get_data(datas, bs=32, aug=None, pixelsize=Resize_pixelsize):\n",
        "    # Data preparation\n",
        "    while True:\n",
        "      file_stream = file_io.FileIO(training_dataset_dir, mode='r')\n",
        "      datas = pd.read_csv(file_stream,iterator=True, chunksize=bs )\n",
        "      for data in datas:\n",
        "          data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "          X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "          X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "          X = X/255.0\n",
        "          X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "          for ind in range(X.shape[0]): \n",
        "              sample = X[ind]\n",
        "              sample = sample.reshape(48, 48)\n",
        "              image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "              X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "          Y_res = np.zeros((Y.size, Y.max()+1))\n",
        "          Y_res[np.arange(Y.size),Y] = 1\n",
        "          if aug is not None:\n",
        "              (X_res, Y_res) = next(aug.flow(np.array(X_res),\n",
        "                  Y_res, batch_size=bs))\n",
        "          yield  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQkWIk2kF0aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/train.csv'\n",
        "dev_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/dev.csv'\n",
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "train_generator = get_data(training_dataset_dir,  bs=BS, aug=None)\n",
        "dev_generator   = get_data(dev_dataset_dir, bs=BS, aug=None)\n",
        "test_generator   = get_data(test_dataset_dir, bs=BS, aug=None)\n",
        "    #X_dev_res, Y_dev_res  = get_data(dev_dataset_dir)\n",
        "\n",
        "# Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches) indefinitely\n",
        "# rescale:          Rescaling factor (defaults to None). Multiply the data by the value provided (before applying any other transformation)\n",
        "# rotation_range:   Int. Degree range for random rotations\n",
        "# shear_range:      Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
        "# zoom_range:       Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range]\n",
        "# fill_mode :       Points outside the boundaries of the input are filled according to the given mode: {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
        "# horizontal_flip:  Boolean. Randomly flip inputs horizontally\n",
        "\n",
        "\n",
        "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "#train_generator = train_datagen.flow(X_train_res, Y_train_res,  batch_size  = BS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pLISdlaStbUn",
        "outputId": "2d4aa3df-8882-4e55-8349-5d2c597ef606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator = train_generator,\n",
        "    validation_data=dev_generator, \n",
        "    steps_per_epoch=28709// BS,\n",
        "    validation_steps=3509 // BS,\n",
        "    shuffle=True,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[rlrop],\n",
        "    use_multiprocessing=True,\n",
        ") "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/100\n",
            "224/224 [==============================] - 176s 786ms/step - loss: 13.6984 - acc: 0.1430 - val_loss: 13.7909 - val_acc: 0.1444\n",
            "Epoch 2/100\n",
            "224/224 [==============================] - 164s 730ms/step - loss: 13.8179 - acc: 0.1427 - val_loss: 13.7209 - val_acc: 0.1487\n",
            "Epoch 3/100\n",
            "224/224 [==============================] - 163s 730ms/step - loss: 13.8140 - acc: 0.1430 - val_loss: 13.8795 - val_acc: 0.1389\n",
            "Epoch 4/100\n",
            " 33/224 [===>..........................] - ETA: 1:53 - loss: 13.7990 - acc: 0.1439"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-2:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 641, in next_sample\n",
            "    return six.next(_SHARED_SEQUENCES[uid])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"<ipython-input-7-7cc7e51c6a7c>\", line 15, in get_data\n",
            "    image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\", line 166, in resize\n",
            "    preserve_range=preserve_range)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py\", line 856, in warp\n",
            "    order=order, mode=mode, cval=cval)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "  File \"skimage/transform/_warps_cy.pyx\", line 183, in skimage.transform._warps_cy._warp_fast\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\", line 16, in asarray\n",
            "    @set_module('numpy')\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cabc5e91c19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrlrop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m ) \n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSSv08SHF0bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on dev data')\n",
        "results_dev = model.evaluate_generator(dev_generator, 3509 // BS)\n",
        "print('dev loss, dev acc:', results_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4sDYDlOsqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "results_test = model.evaluate_generator(test_generator, 3509 // BS)\n",
        "print('test loss, test acc:', results_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9f7smhHUQus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QKHTmJQhi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_str = '-SGD_LR_%.5f' % SGD_LEARNING_RATE\n",
        "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
        "bs_str = '-BS_' + str(BS)\n",
        "dropout_str = '-DROPOUT_' + str(DROPOUT_RATE)\n",
        "test_acc = 'test_acc_%.3f' % results_test[1]\n",
        "model.save('/content/drive/My Drive/cs230 project/models/tl/tl' + lr_str + epoch_str + bs_str + dropout_str + test_acc + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuqHDa5Hwiih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_for_test(dataset, pixelsize = Resize_pixelsize):\n",
        "    file_stream = file_io.FileIO(dataset, mode='r')\n",
        "    data = pd.read_csv(file_stream)\n",
        "    data[' pixels'] = data[' pixels'].apply(lambda x: [int(pixel) for pixel in x.split()])\n",
        "\n",
        "    X, Y = data[' pixels'].tolist(), data['emotion'].values\n",
        "    X = np.array(X, dtype='float32').reshape(-1,48,48,1)\n",
        "    X = X/255.0\n",
        "    X_res = np.zeros((X.shape[0], pixelsize,pixelsize,3))\n",
        "    for ind in range(X.shape[0]):  #X_dev.shape[0]\n",
        "        sample = X[ind]\n",
        "        sample = sample.reshape(48, 48)\n",
        "        image_resized = resize(sample, (pixelsize, pixelsize), anti_aliasing=True)\n",
        "        X_res[ind,:,:,:] = image_resized.reshape(pixelsize,pixelsize,1)\n",
        "\n",
        "    Y_res = np.zeros((Y.size, Y.max()+1))\n",
        "    Y_res[np.arange(Y.size),Y] = 1\n",
        "    \n",
        "    return  X_res, Y_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MAUWRXFxcm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset_dir = '/content/drive/My Drive/cs230 project/collab/fer2013/test.csv'\n",
        "X_test_res, Y_test_res  = get_data_for_test(test_dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulH4ikEJxhm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test_res, Y_test_res)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cHBx0OcUYWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# configure image data augmentation\n",
        "tta_aug = ImageDataGenerator(\n",
        "    # rotation_range  = 10,\n",
        "    # shear_range     = 10, # 10 degrees\n",
        "    # zoom_range      = 0.1,\n",
        "    # fill_mode       = 'reflect',\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "# make a prediction using test-time augmentation\n",
        "def tta_prediction(model, image, n_examples):\n",
        "\t# convert image into dataset\n",
        "\tsamples = np.expand_dims(image, 0)\n",
        "  test_generator = get_data(test_dataset_dir, bs=BS, aug=tta_aug)\n",
        "\tit = test_generator.flow(samples, batch_size=n_examples)\n",
        "\tyhats = model.predict_generator(it, steps=n_examples, verbose=0)\n",
        "\t# sum across predictions\n",
        "\tsummed = np.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\treturn np.argmax(summed)\n",
        " \n",
        " # evaluate a model on a dataset using test-time augmentation\n",
        "def tta_evaluate_model(model, testX, testY):\n",
        "\t# configure image data augmentation\n",
        "\tdatagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\t# define the number of augmented images to generate per test set image\n",
        "\tn_examples_per_image = 7\n",
        "\tyhats = list()\n",
        "\tfor i in range(len(testX)):\n",
        "\t\t# make augmented prediction\n",
        "\t\tyhat = tta_prediction(datagen, model, testX[i], n_examples_per_image)\n",
        "\t\t# store for evaluation\n",
        "\t\tyhats.append(yhat)\n",
        "\t# calculate accuracy\n",
        "\ttestY_labels = np.argmax(testY, axis=1)\n",
        "\tacc = accuracy_score(testY_labels, yhats)\n",
        "\treturn acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78X7l-0txbT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ia-TsrIUf9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n# Evaluate on test data')\n",
        "TTA_results_test = tta_evaluate_model(model, X_test, Y_test)\n",
        "print('test loss, test acc:', results_test)\n",
        "print('TTA test acc:', TTA_results_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}